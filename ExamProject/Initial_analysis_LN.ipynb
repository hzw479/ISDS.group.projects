{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d94043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Liv\n",
      "[nltk_data]     Nøhr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Liv\n",
      "[nltk_data]     Nøhr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Liv\n",
      "[nltk_data]     Nøhr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from the textbook, for printing a process bar.\n",
    "import pyprind\n",
    "\n",
    "# basic packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re # python regular expressions\n",
    "import string # for efficient operations with strings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For creating dictionaries that you can fill in a loop\n",
    "from collections import defaultdict\n",
    "\n",
    "# NLTK: A basic, popular NLP package. Find many examples of applications at https://www.nltk.org/book/\n",
    "# Install guide: https://www.nltk.org/install.html\n",
    "import nltk\n",
    "nltk.download('punkt') # you will probably need to do this\n",
    "nltk.download('wordnet') # and this\n",
    "nltk.download('stopwords') # aand this\n",
    "\n",
    "# for vectorization \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#Vader Lexicon for sentiment analysis\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# similarity/distance measures\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "\n",
    "# for classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Lexicons for sentiment analysis\n",
    "from vaderSentiment import vaderSentiment\n",
    "from afinn import Afinn\n",
    "\n",
    "# to display images in notebook\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc2d13d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Dates</th>\n",
       "      <th>TeacherID</th>\n",
       "      <th>SchoolID</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Professor Acres is incredible--friendly, knowl...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-02</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He is an amazing professor- I definitely recom...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Great!</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-03-23</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Al is an absolutely great professor. His semin...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2007-10-21</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81712</th>\n",
       "      <td>81712</td>\n",
       "      <td>Difficult to understand and not very helpful. ...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2009-12-23</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81713</th>\n",
       "      <td>81713</td>\n",
       "      <td>MUY MAL!! This teacher is unorganized and scat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-12-22</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81714</th>\n",
       "      <td>81714</td>\n",
       "      <td>very sweet disposition -- very willing to help...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-12-20</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81715</th>\n",
       "      <td>81715</td>\n",
       "      <td>This professor is very helpful, wants her stud...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-09-06</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81716</th>\n",
       "      <td>81716</td>\n",
       "      <td>This professor just rox.  She is in possession...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-04-29</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79793 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                           Comments  Quality  \\\n",
       "0               0  Professor Acres is incredible--friendly, knowl...      5.0   \n",
       "1               1  He is an amazing professor- I definitely recom...      5.0   \n",
       "2               2                                             Great!      3.0   \n",
       "3               3                                            Awesome      5.0   \n",
       "4               4  Al is an absolutely great professor. His semin...      5.0   \n",
       "...           ...                                                ...      ...   \n",
       "81712       81712  Difficult to understand and not very helpful. ...      1.5   \n",
       "81713       81713  MUY MAL!! This teacher is unorganized and scat...      1.0   \n",
       "81714       81714  very sweet disposition -- very willing to help...      5.0   \n",
       "81715       81715  This professor is very helpful, wants her stud...      5.0   \n",
       "81716       81716  This professor just rox.  She is in possession...      5.0   \n",
       "\n",
       "       Difficulty       Dates  TeacherID  SchoolID  status  \n",
       "0             4.0  2017-05-02     336888       780     top  \n",
       "1             3.0  2017-04-28     336888       780     top  \n",
       "2             3.0  2012-03-23     336888       780     top  \n",
       "3             1.0  2011-02-01     336888       780     top  \n",
       "4             4.0  2007-10-21     336888       780     top  \n",
       "...           ...         ...        ...       ...     ...  \n",
       "81712         3.0  2009-12-23     608528      4171  bottom  \n",
       "81713         1.0  2005-12-22     608528      4171  bottom  \n",
       "81714         1.0  2005-12-20     608528      4171  bottom  \n",
       "81715         1.0  2005-09-06     608528      4171  bottom  \n",
       "81716         1.0  2005-04-29     608528      4171  bottom  \n",
       "\n",
       "[79793 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_p = pd.read_csv('df_final.csv')\n",
    "df_c = pd.read_csv('df_comments_final.csv')\n",
    "df_c = df_c[df_c['Comments'] != 'No Comments']\n",
    "df_c['Comments'] = df_c['Comments'].dropna()\n",
    "\n",
    "df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c013b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0646958011996572\n",
      "3.6752940718236347\n",
      "   status  Difficulty\n",
      "0  bottom    3.058657\n",
      "1     top    3.085095\n",
      "   status   Quality\n",
      "0  bottom  3.649276\n",
      "1     top  3.763188\n",
      "   status     len_col\n",
      "0  bottom  240.208517\n",
      "1     top  189.889530\n",
      "status\n",
      "bottom    61698\n",
      "top       18095\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_c[\"Difficulty\"].mean())\n",
    "print(df_c[\"Quality\"].mean())\n",
    "\n",
    "\n",
    "#Depending on school status\n",
    "\n",
    "print(df_c.groupby('status', as_index=False)['Difficulty'].mean())\n",
    "print(df_c.groupby('status', as_index=False)['Quality'].mean())\n",
    "\n",
    "#Make column with length of comments\n",
    "df_c['len_col'] = df_c['Comments'].str.len()\n",
    "\n",
    "print(df_c.groupby('status', as_index=False)['len_col'].mean())\n",
    "\n",
    "print(df_c.groupby('status').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34da4c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status   Quality\n",
      "0  bottom  2.179516\n",
      "1     top  2.209166\n",
      "   status  Difficulty\n",
      "0  bottom    1.553341\n",
      "1     top    1.526440\n"
     ]
    }
   ],
   "source": [
    "#See variance\n",
    "\n",
    "print(df_c.groupby('status', as_index=False)['Quality'].var())\n",
    "print(df_c.groupby('status', as_index=False)['Difficulty'].var())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9e3008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Quality', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sns.countplot(data=df_c, x='Difficulty')\n",
    "\n",
    "sns.countplot(data=df_c, x='Quality', hue = 'status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7025c38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='year', ylabel='Comments'>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "df_c['year'] = df_c['Dates'].str[2:4]\n",
    "\n",
    "statgrouped = df_c.groupby([\"status\", \"year\"]).count()\n",
    "\n",
    "statgrouped =statgrouped.groupby(level=[0]).apply(lambda g: g / g.sum())\n",
    "statgrouped=statgrouped.reset_index()\n",
    "\n",
    "statgrouped\n",
    "\n",
    "sns.barplot(data=statgrouped, x='year', y='Comments', hue = 'status')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e40abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('STOPlist.txt') as f:\n",
    "    stoppelop = f.read().splitlines()\n",
    "stoppelop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8d6804f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    low_text= text.lower()\n",
    "    low_text = low_text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(low_text)\n",
    "    porter = nltk.WordNetLemmatizer()\n",
    "    lemmatizer=[porter.lemmatize(t) for t in tokens]\n",
    "    stop_words_list = stoppelop\n",
    "    sent_sw_removed = [i for i in lemmatizer if i not in stop_words_list]\n",
    "    lemmas=[i for i in sent_sw_removed if i!='br']\n",
    "    return lemmas # return a list of stems/lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9b76a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c=df_c[df_c['Comments']!='No Comments'].dropna()\n",
    "\n",
    "df_c['Clean_comment']=df_c.apply(lambda row: preprocess(row.Comments), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a66fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_c['Comments']\n",
    "\n",
    "y = df_c['Quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=161193)\n",
    "\n",
    "\n",
    "# CountVectorizer (from sklearn.feature_extraction.text) has a build-in tokenizer and lowercases by default. It also has an option to remove stopwords (look at the documentation).\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# You can override the default tokenization with your own defined function, like so:\n",
    "vectorizer = CountVectorizer(tokenizer=preprocess)\n",
    "\n",
    "# you can also restrict the number of features to the top N most frequent features:\n",
    "#vectorizer = CountVectorizer(max_features=N)\n",
    "\n",
    "# fit and transform train set\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Only tranform test set: never fit your vectorizer on the test set (it is cheating). Out-of-Vocabulary words are handled automatically be sklearn's vectorizer.\n",
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adb15951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57654, 32583)\n",
      "32583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x32583 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_bow.shape)\n",
    "print(len(vectorizer.vocabulary_))\n",
    "X_train_bow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "390a885e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 25227)\t1\n",
      "  (0, 13553)\t1\n",
      "  (0, 24086)\t1\n",
      "  (0, 28582)\t1\n",
      "  (0, 5929)\t2\n",
      "  (0, 28420)\t3\n",
      "  (0, 31980)\t1\n",
      "  (0, 16024)\t1\n",
      "  (0, 31154)\t2\n",
      "  (0, 3915)\t1\n",
      "  (0, 20101)\t1\n",
      "  (0, 13844)\t1\n",
      "  (0, 22285)\t1\n",
      "  (0, 28459)\t1\n",
      "  (0, 22749)\t1\n",
      "  (0, 12759)\t1\n",
      "helpful\n"
     ]
    }
   ],
   "source": [
    "X_train_bow[0].toarray() # the vector is very sparse..\n",
    "print(X_train_bow[0]) # here we take a look at the non-zero elements. \n",
    "#The first element is the word with ID 25459, which appears two times in the text.\n",
    "print(vectorizer.get_feature_names()[13844]) # this is one way to get the word with the ID 25459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc3aaaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TF_IDF\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5279f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most similar: [  100 55483 57563 37648 11135 22220  4948  3379 23069 35121]\n",
      "least similar [ 2901 15920 34930 15907 34976 44921 53515 34989 52065]\n"
     ]
    }
   ],
   "source": [
    "cosine_similarities = cosine_similarity(X_train_tfidf[100], X_train_tfidf).flatten()\n",
    "\n",
    "indices = cosine_similarities.argsort()[::-1] # in descending order \n",
    "print(\"most similar:\",indices[:10])\n",
    "print(\"least similar\", indices[-9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c9a7def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professor Brinton was an amazing professor and really helped me through the class. He was readily available for questions and puts a lot of time into his courses. I would highly recommend him if you have the opportunity to take one of his classes.\n",
      "\n",
      "most similar:  Marcus was very helpful when i was confused.  Great teacher to have.\n",
      "\n",
      "least similar:  Great. Very well-read and informed. Brings a global perspective to his class which most Americans do not.\n"
     ]
    }
   ],
   "source": [
    "print(X_train[100])\n",
    "print()\n",
    "print(\"most similar: \", X_train[55483  ])\n",
    "print()\n",
    "print(\"least similar: \", X_train[2901  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52c0a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "X = df_c['Clean_comment']\n",
    "\n",
    "y = df_c['Quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=161193)\n",
    "\n",
    "\n",
    "# using the train_sents from earlier (the lowercased and tokenized sentences)\n",
    "model = Word2Vec(X_train, vector_size=50)#the default learning algorithm is CBOW. To use skip-gram use the paramter sg=1.\n",
    "\n",
    "# You can load pretrained embeddings downloaded from: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing \n",
    "# BUT this takes up a lot of space (the file is over 1 GB) and a lot of RAM when you try to use it.\n",
    "# If you want to try it, write this:\n",
    "#model = gensim.models.KeyedVectors.load_word2vec_format(directory_path+'GoogleNews-vectors-negative300.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2febb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3427301 ,  1.6213628 ,  0.18186499, -0.6462621 ,  0.19362907,\n",
       "       -1.1867796 ,  2.288043  , -0.22551453,  2.7086349 ,  0.43891525,\n",
       "        2.292423  , -0.9978531 ,  1.0667039 ,  0.7378389 ,  0.45770636,\n",
       "        1.1756386 ,  0.5812719 ,  0.38641572, -2.8912237 , -1.594051  ,\n",
       "        1.8976976 ,  0.00520311,  1.3018486 ,  0.22148238, -0.9200242 ,\n",
       "       -0.12997903,  1.2154835 ,  1.8347392 ,  0.01004102, -0.37225938,\n",
       "       -1.2753783 , -1.0325412 ,  1.5503664 , -0.51728296,  0.36603075,\n",
       "        0.7540513 ,  0.63373584, -0.46928576, -0.09215516,  2.1362817 ,\n",
       "        0.10410433, -0.05551953,  0.3986686 , -1.0420195 ,  2.4545798 ,\n",
       "       -0.7012055 , -0.49838266, -0.7577969 ,  0.7570233 ,  0.20809633],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['professor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "edb00ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reducing the 50-dimensional vectors to 2 dimensions in order to visualise selected words.\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "words = [\"test\",\"easy\", \"teacher\", \"ta\", \"bad\", \"horrible\", \"time\", \"expensive\", \"hot\", \"never\"]\n",
    "\n",
    "X = [model.wv['test'], model.wv['easy'], \n",
    "     model.wv['teacher'], model.wv['ta'], \n",
    "     model.wv['bad'], model.wv['horrible'], \n",
    "     model.wv['time'], model.wv['expensive'],\n",
    "     model.wv['hot'], model.wv['never']]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit(X).transform(X)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(X_r[:,0], X_r[:,1], edgecolors='k', c='r')\n",
    "for word, (x,y) in zip(words, X_r):\n",
    "    plt.text(x+0.2, y+0.1, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "258c72d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-84-a7855ecdb29a>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  embedded_text = np.array([np.mean([model.wv[w] if w in model.wv.key_to_index.keys() else np.zeros(50) for w in words], axis=0) for words in X_train])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-a7855ecdb29a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Using the averaged word2vec document embeddings to find similar documents:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcosine_similarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedded_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# in descending order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"most similar:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;31m# to avoid recursive import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    147\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                         estimator=estimator)\n\u001b[1;32m--> 149\u001b[1;33m         Y = check_array(Y, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[0m\u001b[0;32m    150\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                         estimator=estimator)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "###SE PÅ SENERE\n",
    "\n",
    "embedded_text = np.array([np.mean([model.wv[w] if w in model.wv.key_to_index.keys() else np.zeros(50) for w in words], axis=0) for words in X_train])\n",
    "\n",
    "\n",
    "# Using the averaged word2vec document embeddings to find similar documents:\n",
    "cosine_similarities = cosine_similarity(embedded_text[0].reshape(1,50), embedded_text[:]).flatten()\n",
    "indices = cosine_similarities.argsort()[::-1] # in descending order \n",
    "print(\"most similar:\",indices[:10])\n",
    "print(\"least similar\", indices[-9:])\n",
    "print(X_train[0])\n",
    "print()\n",
    "print(\"most similar: \", X_train[5052])\n",
    "print()\n",
    "print(\"least similar: \", X_train[22007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6939314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76872\n",
      "76872\n"
     ]
    }
   ],
   "source": [
    "y = np.where(df_c['Quality']>=3.5, 'good', 'bad')\n",
    "\n",
    "X = df_c['Comments']\n",
    "\n",
    "np.where(df_c['Quality']>=3.5, 'good', 'bad')\n",
    "   \n",
    "\n",
    "print(len(y))\n",
    "print(len(X))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=161193)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a70e47ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.8362646130363895\n",
      "testing accuracy: 0.8092933707982101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Get feature vectors\n",
    "tfidf = TfidfVectorizer()\n",
    "# use your own preprocessing function in the vectorizer when you've finished that exercise:\n",
    "#tfidf = TfidfVectorizer(tokenizer=preprocess)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# labels\n",
    "y_train = y_train\n",
    "y_test = y_test\n",
    "\n",
    "# classifier\n",
    "lr = LogisticRegression(random_state=0)\n",
    "\n",
    "#training\n",
    "lr.fit(X_train_tfidf,y_train)\n",
    "\n",
    "#testing\n",
    "train_preds = lr.predict(X_train_tfidf)\n",
    "test_preds = lr.predict(X_test_tfidf)\n",
    "print(\"training accuracy:\", np.mean([(train_preds==y_train)]))\n",
    "print(\"testing accuracy:\", np.mean([(test_preds==y_test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f0bcaef1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000001g</th>\n",
       "      <th>0006</th>\n",
       "      <th>001</th>\n",
       "      <th>0010</th>\n",
       "      <th>002</th>\n",
       "      <th>004</th>\n",
       "      <th>005</th>\n",
       "      <th>0072558318</th>\n",
       "      <th>...</th>\n",
       "      <th>ás</th>\n",
       "      <th>útil</th>\n",
       "      <th>ōlelo</th>\n",
       "      <th>ʻana</th>\n",
       "      <th>ʻike</th>\n",
       "      <th>ʻo</th>\n",
       "      <th>ʻoe</th>\n",
       "      <th>ʻoluʻolu</th>\n",
       "      <th>ʻoʻoleʻa</th>\n",
       "      <th>爸爸</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048164</td>\n",
       "      <td>-0.137459</td>\n",
       "      <td>-0.117054</td>\n",
       "      <td>-0.064267</td>\n",
       "      <td>-0.220373</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.020846</td>\n",
       "      <td>0.019865</td>\n",
       "      <td>0.081524</td>\n",
       "      <td>-0.111459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187838</td>\n",
       "      <td>0.072255</td>\n",
       "      <td>0.020433</td>\n",
       "      <td>0.045995</td>\n",
       "      <td>0.045995</td>\n",
       "      <td>0.091989</td>\n",
       "      <td>0.045995</td>\n",
       "      <td>0.045995</td>\n",
       "      <td>0.045995</td>\n",
       "      <td>0.140488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000   000001g      0006       001      0010       002  \\\n",
       "0  0.048164 -0.137459 -0.117054 -0.064267 -0.220373  0.084337  0.020846   \n",
       "\n",
       "        004       005  0072558318  ...        ás      útil     ōlelo  \\\n",
       "0  0.019865  0.081524   -0.111459  ...  0.187838  0.072255  0.020433   \n",
       "\n",
       "       ʻana      ʻike        ʻo       ʻoe  ʻoluʻolu  ʻoʻoleʻa        爸爸  \n",
       "0  0.045995  0.045995  0.091989  0.045995  0.045995  0.045995  0.140488  \n",
       "\n",
       "[1 rows x 28328 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['_'.join(s.split()) for s in tfidf.get_feature_names()]\n",
    "coefficients = lr.coef_\n",
    "coefs_df = pd.DataFrame.from_records(coefficients, columns=features)\n",
    "coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f65dc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0\n",
      "great         4.665930\n",
      "amazing       4.644933\n",
      "best          4.631600\n",
      "excellent     4.494046\n",
      "awesome       3.950368\n",
      "wonderful     3.724243\n",
      "helpful       3.477301\n",
      "loved         3.052912\n",
      "hilarious     2.875124\n",
      "fun           2.809272\n",
      "fantastic     2.733415\n",
      "highly        2.700198\n",
      "interesting   2.686381\n",
      "cool          2.684344\n",
      "explains      2.669693\n",
      "cares         2.561864\n",
      "rocks         2.544533\n",
      "favorite      2.536366\n",
      "easy          2.446267\n",
      "enthusiastic  2.414573\n",
      "\n",
      "                    0\n",
      "worst       -6.675677\n",
      "not         -5.295324\n",
      "avoid       -4.584834\n",
      "unclear     -4.035717\n",
      "horrible    -3.625365\n",
      "rude        -3.549601\n",
      "useless     -3.503210\n",
      "luck        -3.413324\n",
      "confusing   -3.302065\n",
      "terrible    -3.284915\n",
      "poor        -3.196714\n",
      "nothing     -3.061069\n",
      "awful       -2.933359\n",
      "unorganized -2.867737\n",
      "unhelpful   -2.847724\n",
      "doesn       -2.843693\n",
      "reads       -2.640829\n",
      "yourself    -2.564195\n",
      "thinks      -2.547505\n",
      "vague       -2.538503\n"
     ]
    }
   ],
   "source": [
    "print(coefs_df.T.sort_values(by=[0], ascending=False).head(20))\n",
    "print()\n",
    "print(coefs_df.T.sort_values(by=[0], ascending=True).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae8336",
   "metadata": {},
   "source": [
    "## De faktisk modeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "237bfd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = df_c[df_c['status']=='top']\n",
    "bottom = df_c[df_c['status']=='bottom']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "99554eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top universities\n",
    "y_t = np.where(top['Quality']>=3.5, 'good', 'bad')\n",
    "\n",
    "X_t = top['Comments']\n",
    "\n",
    "Xt_train, Xt_test, yt_train, yt_test = train_test_split(X_t, y_t, random_state=161193)\n",
    "\n",
    "#bottom universities\n",
    "y_b = np.where(bottom['Quality']>=3.5, 'good', 'bad')\n",
    "\n",
    "X_b = bottom['Comments']\n",
    "\n",
    "Xb_train, Xb_test, yb_train, yb_test = train_test_split(X_b, y_b, random_state=161193)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e5eb479a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-e9e27b5fc8f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# use your own preprocessing function in the vectorizer when you've finished that exercise:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#tfidf = TfidfVectorizer(tokenizer=preprocess)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mXt_train_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mXt_test_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \"\"\"\n\u001b[0;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1850\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1851\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1204\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[0;32m    218\u001b[0m                              \"unicode string.\")\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "# Get feature vectors\n",
    "tfidf = TfidfVectorizer()\n",
    "# use your own preprocessing function in the vectorizer when you've finished that exercise:\n",
    "#tfidf = TfidfVectorizer(tokenizer=preprocess)\n",
    "Xt_train_tfidf = tfidf.fit_transform(Xt_train)\n",
    "Xt_test_tfidf = tfidf.transform(Xt_test)\n",
    "\n",
    "# labels\n",
    "yt_train = yt_train\n",
    "yt_test = yt_test\n",
    "\n",
    "# classifier\n",
    "lr = LogisticRegression(random_state=0)\n",
    "\n",
    "#training\n",
    "lr.fit(Xt_train_tfidf,yt_train)\n",
    "\n",
    "#testing\n",
    "ttrain_preds = lr.predict(Xt_train_tfidf)\n",
    "ttest_preds = lr.predict(Xt_test_tfidf)\n",
    "print(\"training accuracy:\", np.mean([(ttrain_preds==yt_train)]))\n",
    "print(\"testing accuracy:\", np.mean([(ttest_preds==yt_test)]))\n",
    "\n",
    "print(coefs_df.T.sort_values(by=[0], ascending=False).head(20))\n",
    "print()\n",
    "print(coefs_df.T.sort_values(by=[0], ascending=True).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ce6d43a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-ee1ab3670e7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcoefficients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcoefs_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcoefs_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1298\u001b[0m         \"\"\"\n\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1300\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m         return [t for t, i in sorted(self.vocabulary_.items(),\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Vocabulary not fitted or provided\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "features = ['_'.join(s.split()) for s in tfidf.get_feature_names()]\n",
    "coefficients = lr.coef_\n",
    "coefs_df = pd.DataFrame.from_records(coefficients, columns=features)\n",
    "coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "78b7782f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0\n",
      "best       4.550059\n",
      "amazing    4.030124\n",
      "great      3.944210\n",
      "excellent  3.415934\n",
      "awesome    3.102986\n",
      "wonderful  2.721556\n",
      "loved      2.646081\n",
      "always     2.541157\n",
      "fantastic  2.474019\n",
      "love       2.444734\n",
      "brilliant  2.424629\n",
      "helpful    2.406449\n",
      "explains   2.336687\n",
      "highly     2.276719\n",
      "willing    2.181848\n",
      "cares      2.173476\n",
      "cool       2.133345\n",
      "sure       1.929296\n",
      "good       1.927644\n",
      "clear      1.898594\n",
      "\n",
      "                     0\n",
      "worst        -6.463011\n",
      "not          -5.909493\n",
      "terrible     -3.902084\n",
      "horrible     -3.753817\n",
      "unclear      -3.414217\n",
      "avoid        -3.110569\n",
      "no           -2.929982\n",
      "rude         -2.792904\n",
      "useless      -2.704012\n",
      "doesn        -2.635714\n",
      "thinks       -2.546257\n",
      "poor         -2.484423\n",
      "unhelpful    -2.437398\n",
      "confusing    -2.309770\n",
      "himself      -2.258127\n",
      "luck         -2.213404\n",
      "awful        -2.149665\n",
      "don          -2.147540\n",
      "disorganized -2.131567\n",
      "seems        -2.030893\n"
     ]
    }
   ],
   "source": [
    "print(coefs_df.T.sort_values(by=[0], ascending=False).head(20))\n",
    "print()\n",
    "print(coefs_df.T.sort_values(by=[0], ascending=True).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "75a9da3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.8309973045822102\n",
      "testing accuracy: 0.7981805929919138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Get feature vectors\n",
    "tfidf = TfidfVectorizer()\n",
    "# use your own preprocessing function in the vectorizer when you've finished that exercise:\n",
    "#tfidf = TfidfVectorizer(tokenizer=preprocess)\n",
    "Xb_train_tfidf = tfidf.fit_transform(Xb_train)\n",
    "Xb_test_tfidf = tfidf.transform(Xb_test)\n",
    "\n",
    "# labels\n",
    "yb_train = yb_train\n",
    "yb_test = yb_test\n",
    "\n",
    "# classifier\n",
    "lr = LogisticRegression(random_state=0)\n",
    "\n",
    "#training\n",
    "lr.fit(Xb_train_tfidf,yb_train)\n",
    "\n",
    "#testing\n",
    "train_preds = lr.predict(Xb_train_tfidf)\n",
    "test_preds = lr.predict(Xb_test_tfidf)\n",
    "print(\"training accuracy:\", np.mean([(train_preds==yb_train)]))\n",
    "print(\"testing accuracy:\", np.mean([(test_preds==yb_test)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4f16309f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000001g</th>\n",
       "      <th>0006</th>\n",
       "      <th>001</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>012</th>\n",
       "      <th>...</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>álvarez</th>\n",
       "      <th>ás</th>\n",
       "      <th>ōlelo</th>\n",
       "      <th>ʻana</th>\n",
       "      <th>ʻike</th>\n",
       "      <th>ʻo</th>\n",
       "      <th>ʻoe</th>\n",
       "      <th>ʻoluʻolu</th>\n",
       "      <th>ʻoʻoleʻa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.153968</td>\n",
       "      <td>-0.652141</td>\n",
       "      <td>-0.117905</td>\n",
       "      <td>-0.068689</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>-0.098886</td>\n",
       "      <td>0.119629</td>\n",
       "      <td>-0.273118</td>\n",
       "      <td>0.077714</td>\n",
       "      <td>0.077714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311484</td>\n",
       "      <td>0.175997</td>\n",
       "      <td>0.186505</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.043434</td>\n",
       "      <td>0.043434</td>\n",
       "      <td>0.086868</td>\n",
       "      <td>0.043434</td>\n",
       "      <td>0.043434</td>\n",
       "      <td>0.043434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000   000001g      0006       001      00am      00pm  \\\n",
       "0 -0.153968 -0.652141 -0.117905 -0.068689  0.041939 -0.098886  0.119629   \n",
       "\n",
       "         01       011       012  ...  zzzzzzzzzzzzzzzzzzzzzz   álvarez  \\\n",
       "0 -0.273118  0.077714  0.077714  ...               -0.311484  0.175997   \n",
       "\n",
       "         ás     ōlelo      ʻana      ʻike        ʻo       ʻoe  ʻoluʻolu  \\\n",
       "0  0.186505  0.020482  0.043434  0.043434  0.086868  0.043434  0.043434   \n",
       "\n",
       "   ʻoʻoleʻa  \n",
       "0  0.043434  \n",
       "\n",
       "[1 rows x 23113 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['_'.join(s.split()) for s in tfidf.get_feature_names()]\n",
    "coefficients = lr.coef_\n",
    "coefs_df = pd.DataFrame.from_records(coefficients, columns=features)\n",
    "coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7d826e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0\n",
      "great        5.166606\n",
      "best         4.433569\n",
      "awesome      4.165015\n",
      "amazing      3.978236\n",
      "excellent    3.808891\n",
      "helpful      3.583302\n",
      "fun          3.354404\n",
      "wonderful    3.218319\n",
      "interesting  2.869070\n",
      "hilarious    2.845134\n",
      "easy         2.829384\n",
      "loved        2.741220\n",
      "cool         2.438599\n",
      "you          2.332321\n",
      "highly       2.320102\n",
      "cares        2.227371\n",
      "love         2.207271\n",
      "enjoyable    2.188529\n",
      "attention    2.125369\n",
      "favorite     2.070249\n",
      "\n",
      "                    0\n",
      "worst       -5.966652\n",
      "not         -5.182568\n",
      "avoid       -4.523254\n",
      "unclear     -4.076124\n",
      "rude        -3.783279\n",
      "horrible    -3.416215\n",
      "luck        -3.343650\n",
      "unorganized -3.159193\n",
      "reads       -3.144532\n",
      "useless     -3.055804\n",
      "nothing     -3.039199\n",
      "confusing   -3.018885\n",
      "terrible    -2.733022\n",
      "doesn       -2.620068\n",
      "awful       -2.575519\n",
      "unhelpful   -2.438693\n",
      "yourself    -2.377456\n",
      "no          -2.351225\n",
      "sucks       -2.273980\n",
      "never       -2.245244\n"
     ]
    }
   ],
   "source": [
    "print(coefs_df.T.sort_values(by=[0], ascending=False).head(20))\n",
    "print()\n",
    "print(coefs_df.T.sort_values(by=[0], ascending=True).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a094e3",
   "metadata": {},
   "source": [
    "## TOP OR BOTTOM???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f93565e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df_c.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "\n",
    "#bottom universities\n",
    "y= df_c['status']\n",
    "\n",
    "X = df_c['Comments']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=161193)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3d09ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your own preprocessing function in the vectorizer when you've finished that exercise:\n",
    "tfidf = TfidfVectorizer(tokenizer=preprocess)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9d3fcb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.8313733652478579\n",
      "testing accuracy: 0.8029451555833074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# labels\n",
    "y_train = y_train\n",
    "y_test = y_test\n",
    "\n",
    "# classifier\n",
    "lr = LogisticRegression(random_state=0)\n",
    "\n",
    "#training\n",
    "lr.fit(X_train_tfidf,y_train)\n",
    "\n",
    "#testing\n",
    "train_preds = lr.predict(X_train_tfidf)\n",
    "test_preds = lr.predict(X_test_tfidf)\n",
    "print(\"training accuracy:\", np.mean([(train_preds==y_train)]))\n",
    "print(\"testing accuracy:\", np.mean([(test_preds==y_test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6f4e0f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0000001g</th>\n",
       "      <th>0006</th>\n",
       "      <th>001</th>\n",
       "      <th>0010</th>\n",
       "      <th>004</th>\n",
       "      <th>01</th>\n",
       "      <th>010</th>\n",
       "      <th>02</th>\n",
       "      <th>025</th>\n",
       "      <th>...</th>\n",
       "      <th>ʻoʻoleʻa</th>\n",
       "      <th>–</th>\n",
       "      <th>–intext</th>\n",
       "      <th>–keep</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>爸爸</th>\n",
       "      <th>��</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.531075</td>\n",
       "      <td>-0.035495</td>\n",
       "      <td>-0.035358</td>\n",
       "      <td>-0.290047</td>\n",
       "      <td>0.189124</td>\n",
       "      <td>0.21841</td>\n",
       "      <td>0.173312</td>\n",
       "      <td>0.077042</td>\n",
       "      <td>-0.53569</td>\n",
       "      <td>-0.155601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066385</td>\n",
       "      <td>0.036056</td>\n",
       "      <td>-0.01221</td>\n",
       "      <td>-0.01221</td>\n",
       "      <td>-0.138332</td>\n",
       "      <td>-1.044916</td>\n",
       "      <td>-0.077821</td>\n",
       "      <td>-0.137498</td>\n",
       "      <td>0.321493</td>\n",
       "      <td>-0.469866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  0000001g      0006       001      0010      004        01  \\\n",
       "0 -0.531075 -0.035495 -0.035358 -0.290047  0.189124  0.21841  0.173312   \n",
       "\n",
       "        010       02       025  ...  ʻoʻoleʻa         –  –intext    –keep  \\\n",
       "0  0.077042 -0.53569 -0.155601  ... -0.066385  0.036056 -0.01221 -0.01221   \n",
       "\n",
       "          ‘         ’         “         ”        爸爸        ��  \n",
       "0 -0.138332 -1.044916 -0.077821 -0.137498  0.321493 -0.469866  \n",
       "\n",
       "[1 rows x 27114 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['_'.join(s.split()) for s in tfidf.get_feature_names()]\n",
    "coefficients = lr.coef_\n",
    "coefs_df = pd.DataFrame.from_records(coefficients, columns=features)\n",
    "coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a810f71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0\n",
      "cal           8.335027\n",
      "calu          5.395778\n",
      "jhu           4.648602\n",
      "mit           4.480599\n",
      "d2l           4.188520\n",
      "lecturer      4.044410\n",
      "orgo          3.493590\n",
      "bonus         3.436890\n",
      "brilliant     2.853486\n",
      "china         2.752921\n",
      "backtests     2.536598\n",
      "quarter       2.524976\n",
      "neuroscience  2.267510\n",
      "psets         2.129070\n",
      "engaging      2.046909\n",
      "pwr           1.956871\n",
      "linear        1.910469\n",
      "prof          1.890996\n",
      "uchicago      1.851459\n",
      "genius        1.845722\n",
      "incredible    1.815084\n",
      "mathematical  1.786480\n",
      "leading       1.760825\n",
      "generally     1.751442\n",
      "rewarding     1.730306\n",
      "nobel         1.725902\n",
      "cussw         1.720458\n",
      "eloquent      1.691061\n",
      "algorithm     1.663849\n",
      "excitement    1.653088\n",
      "introduction  1.647592\n",
      "intellectual  1.637659\n",
      "persian       1.634798\n",
      "doc           1.608832\n",
      "incredibly    1.597328\n",
      "analytical    1.596375\n",
      "quantum       1.592416\n",
      "ssa           1.589010\n",
      "team          1.573766\n",
      "committed     1.536336\n",
      "\n",
      "                    0\n",
      "csu         -6.383536\n",
      "wsu         -5.152365\n",
      "wku         -4.991563\n",
      "twu         -4.382843\n",
      "pba         -3.591734\n",
      "mr          -3.016988\n",
      "expectation -2.894613\n",
      "test        -2.847850\n",
      "quiz        -2.742154\n",
      "pas         -2.531837\n",
      "ut          -2.527156\n",
      "guide       -2.484341\n",
      "semester    -2.451538\n",
      "credit      -2.310881\n",
      "chapter     -2.301266\n",
      "board       -2.232024\n",
      "expects     -2.212190\n",
      "succeed     -2.173650\n",
      "passed      -2.168013\n",
      "instructor  -2.135665\n",
      "review      -2.052852\n",
      "hybrid      -2.021061\n",
      "sarcastic   -2.003423\n",
      "module      -1.969526\n",
      "essay       -1.964115\n",
      "ready       -1.954181\n",
      "utt         -1.952394\n",
      "blackboard  -1.943114\n",
      "video       -1.934475\n",
      "grade       -1.926038\n",
      "respectful  -1.925373\n",
      "homework    -1.899258\n",
      "email       -1.898696\n",
      "uhh         -1.836570\n",
      "teacher     -1.835543\n",
      "prepare     -1.827029\n",
      "asl         -1.822846\n",
      "artist      -1.813285\n",
      "group       -1.810449\n",
      "provides    -1.799014\n"
     ]
    }
   ],
   "source": [
    "print(coefs_df.T.sort_values(by=[0], ascending=False).head(40))\n",
    "print()\n",
    "print(coefs_df.T.sort_values(by=[0], ascending=True).head(40))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
