{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44d94043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Liv\n",
      "[nltk_data]     Nøhr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Liv\n",
      "[nltk_data]     Nøhr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Liv\n",
      "[nltk_data]     Nøhr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from the textbook, for printing a process bar.\n",
    "import pyprind\n",
    "\n",
    "# basic packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re # python regular expressions\n",
    "import string # for efficient operations with strings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For creating dictionaries that you can fill in a loop\n",
    "from collections import defaultdict\n",
    "\n",
    "# NLTK: A basic, popular NLP package. Find many examples of applications at https://www.nltk.org/book/\n",
    "# Install guide: https://www.nltk.org/install.html\n",
    "import nltk\n",
    "nltk.download('punkt') # you will probably need to do this\n",
    "nltk.download('wordnet') # and this\n",
    "nltk.download('stopwords') # aand this\n",
    "\n",
    "# for vectorization \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#Vader Lexicon for sentiment analysis\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# similarity/distance measures\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "\n",
    "# for classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Lexicons for sentiment analysis\n",
    "from vaderSentiment import vaderSentiment\n",
    "from afinn import Afinn\n",
    "\n",
    "# to display images in notebook\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2d13d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Dates</th>\n",
       "      <th>TeacherID</th>\n",
       "      <th>SchoolID</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Professor Acres is incredible--friendly, knowl...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-02</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He is an amazing professor- I definitely recom...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Great!</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-03-23</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Al is an absolutely great professor. His semin...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2007-10-21</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81712</th>\n",
       "      <td>81712</td>\n",
       "      <td>Difficult to understand and not very helpful. ...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2009-12-23</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81713</th>\n",
       "      <td>81713</td>\n",
       "      <td>MUY MAL!! This teacher is unorganized and scat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-12-22</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81714</th>\n",
       "      <td>81714</td>\n",
       "      <td>very sweet disposition -- very willing to help...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-12-20</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81715</th>\n",
       "      <td>81715</td>\n",
       "      <td>This professor is very helpful, wants her stud...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-09-06</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81716</th>\n",
       "      <td>81716</td>\n",
       "      <td>This professor just rox.  She is in possession...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-04-29</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79793 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                           Comments  Quality  \\\n",
       "0               0  Professor Acres is incredible--friendly, knowl...      5.0   \n",
       "1               1  He is an amazing professor- I definitely recom...      5.0   \n",
       "2               2                                             Great!      3.0   \n",
       "3               3                                            Awesome      5.0   \n",
       "4               4  Al is an absolutely great professor. His semin...      5.0   \n",
       "...           ...                                                ...      ...   \n",
       "81712       81712  Difficult to understand and not very helpful. ...      1.5   \n",
       "81713       81713  MUY MAL!! This teacher is unorganized and scat...      1.0   \n",
       "81714       81714  very sweet disposition -- very willing to help...      5.0   \n",
       "81715       81715  This professor is very helpful, wants her stud...      5.0   \n",
       "81716       81716  This professor just rox.  She is in possession...      5.0   \n",
       "\n",
       "       Difficulty       Dates  TeacherID  SchoolID  status  \n",
       "0             4.0  2017-05-02     336888       780     top  \n",
       "1             3.0  2017-04-28     336888       780     top  \n",
       "2             3.0  2012-03-23     336888       780     top  \n",
       "3             1.0  2011-02-01     336888       780     top  \n",
       "4             4.0  2007-10-21     336888       780     top  \n",
       "...           ...         ...        ...       ...     ...  \n",
       "81712         3.0  2009-12-23     608528      4171  bottom  \n",
       "81713         1.0  2005-12-22     608528      4171  bottom  \n",
       "81714         1.0  2005-12-20     608528      4171  bottom  \n",
       "81715         1.0  2005-09-06     608528      4171  bottom  \n",
       "81716         1.0  2005-04-29     608528      4171  bottom  \n",
       "\n",
       "[79793 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_p = pd.read_csv('df_final.csv')\n",
    "df_c = pd.read_csv('df_comments_final.csv')\n",
    "df_c = df_c[df_c['Comments'] != 'No Comments']\n",
    "df_c['Comments'] = df_c['Comments'].dropna()\n",
    "\n",
    "df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c013b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0646958011996572\n",
      "3.6752940718236347\n",
      "   status  Difficulty\n",
      "0  bottom    3.058657\n",
      "1     top    3.085095\n",
      "   status   Quality\n",
      "0  bottom  3.649276\n",
      "1     top  3.763188\n",
      "   status     len_col\n",
      "0  bottom  240.208517\n",
      "1     top  189.889530\n",
      "status\n",
      "bottom    61698\n",
      "top       18095\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_c[\"Difficulty\"].mean())\n",
    "print(df_c[\"Quality\"].mean())\n",
    "\n",
    "\n",
    "#Depending on school status\n",
    "\n",
    "print(df_c.groupby('status', as_index=False)['Difficulty'].mean())\n",
    "print(df_c.groupby('status', as_index=False)['Quality'].mean())\n",
    "\n",
    "#Make column with length of comments\n",
    "df_c['len_col'] = df_c['Comments'].str.len()\n",
    "\n",
    "print(df_c.groupby('status', as_index=False)['len_col'].mean())\n",
    "\n",
    "print(df_c.groupby('status').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34da4c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status   Quality\n",
      "0  bottom  2.179516\n",
      "1     top  2.209166\n",
      "   status  Difficulty\n",
      "0  bottom    1.553341\n",
      "1     top    1.526440\n"
     ]
    }
   ],
   "source": [
    "#See variance\n",
    "\n",
    "print(df_c.groupby('status', as_index=False)['Quality'].var())\n",
    "print(df_c.groupby('status', as_index=False)['Difficulty'].var())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf9e3008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Quality', ylabel='count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sns.countplot(data=df_c, x='Difficulty')\n",
    "\n",
    "sns.countplot(data=df_c, x='Quality', hue = 'status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f7ee331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Dates</th>\n",
       "      <th>TeacherID</th>\n",
       "      <th>SchoolID</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Professor Acres is incredible--friendly, knowl...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-02</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He is an amazing professor- I definitely recom...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Great!</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-03-23</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Al is an absolutely great professor. His semin...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2007-10-21</td>\n",
       "      <td>336888</td>\n",
       "      <td>780</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81712</th>\n",
       "      <td>81712</td>\n",
       "      <td>Difficult to understand and not very helpful. ...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2009-12-23</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81713</th>\n",
       "      <td>81713</td>\n",
       "      <td>MUY MAL!! This teacher is unorganized and scat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-12-22</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81714</th>\n",
       "      <td>81714</td>\n",
       "      <td>very sweet disposition -- very willing to help...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-12-20</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81715</th>\n",
       "      <td>81715</td>\n",
       "      <td>This professor is very helpful, wants her stud...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-09-06</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81716</th>\n",
       "      <td>81716</td>\n",
       "      <td>This professor just rox.  She is in possession...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-04-29</td>\n",
       "      <td>608528</td>\n",
       "      <td>4171</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79793 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                           Comments  Quality  \\\n",
       "0               0  Professor Acres is incredible--friendly, knowl...      5.0   \n",
       "1               1  He is an amazing professor- I definitely recom...      5.0   \n",
       "2               2                                             Great!      3.0   \n",
       "3               3                                            Awesome      5.0   \n",
       "4               4  Al is an absolutely great professor. His semin...      5.0   \n",
       "...           ...                                                ...      ...   \n",
       "81712       81712  Difficult to understand and not very helpful. ...      1.5   \n",
       "81713       81713  MUY MAL!! This teacher is unorganized and scat...      1.0   \n",
       "81714       81714  very sweet disposition -- very willing to help...      5.0   \n",
       "81715       81715  This professor is very helpful, wants her stud...      5.0   \n",
       "81716       81716  This professor just rox.  She is in possession...      5.0   \n",
       "\n",
       "       Difficulty       Dates  TeacherID  SchoolID  status  \n",
       "0             4.0  2017-05-02     336888       780     top  \n",
       "1             3.0  2017-04-28     336888       780     top  \n",
       "2             3.0  2012-03-23     336888       780     top  \n",
       "3             1.0  2011-02-01     336888       780     top  \n",
       "4             4.0  2007-10-21     336888       780     top  \n",
       "...           ...         ...        ...       ...     ...  \n",
       "81712         3.0  2009-12-23     608528      4171  bottom  \n",
       "81713         1.0  2005-12-22     608528      4171  bottom  \n",
       "81714         1.0  2005-12-20     608528      4171  bottom  \n",
       "81715         1.0  2005-09-06     608528      4171  bottom  \n",
       "81716         1.0  2005-04-29     608528      4171  bottom  \n",
       "\n",
       "[79793 rows x 8 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d6804f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    low_text= text.lower()\n",
    "    low_text = low_text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(low_text)\n",
    "    porter = nltk.WordNetLemmatizer()\n",
    "    lemmatizer=[porter.lemmatize(t) for t in tokens]\n",
    "    stop_words_list = nltk.corpus.stopwords.words(\"english\")\n",
    "    sent_sw_removed = [i for i in lemmatizer if i not in stop_words_list]\n",
    "    lemmas=[i for i in sent_sw_removed if i!='br']\n",
    "    return lemmas # return a list of stems/lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9b76a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c=df_c[df_c['Comments']!='No Comments'].dropna()\n",
    "\n",
    "df_c['Clean_comment']=df_c.apply(lambda row: preprocess(row.Comments), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a66fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_c['Comments']\n",
    "\n",
    "y = df_c['Quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=161193)\n",
    "\n",
    "\n",
    "# CountVectorizer (from sklearn.feature_extraction.text) has a build-in tokenizer and lowercases by default. It also has an option to remove stopwords (look at the documentation).\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# You can override the default tokenization with your own defined function, like so:\n",
    "vectorizer = CountVectorizer(tokenizer=preprocess)\n",
    "\n",
    "# you can also restrict the number of features to the top N most frequent features:\n",
    "#vectorizer = CountVectorizer(max_features=N)\n",
    "\n",
    "# fit and transform train set\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Only tranform test set: never fit your vectorizer on the test set (it is cheating). Out-of-Vocabulary words are handled automatically be sklearn's vectorizer.\n",
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adb15951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57654, 32583)\n",
      "32583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x32583 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_bow.shape)\n",
    "print(len(vectorizer.vocabulary_))\n",
    "X_train_bow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "390a885e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 25227)\t1\n",
      "  (0, 13553)\t1\n",
      "  (0, 24086)\t1\n",
      "  (0, 28582)\t1\n",
      "  (0, 5929)\t2\n",
      "  (0, 28420)\t3\n",
      "  (0, 31980)\t1\n",
      "  (0, 16024)\t1\n",
      "  (0, 31154)\t2\n",
      "  (0, 3915)\t1\n",
      "  (0, 20101)\t1\n",
      "  (0, 13844)\t1\n",
      "  (0, 22285)\t1\n",
      "  (0, 28459)\t1\n",
      "  (0, 22749)\t1\n",
      "  (0, 12759)\t1\n",
      "helpful\n"
     ]
    }
   ],
   "source": [
    "X_train_bow[0].toarray() # the vector is very sparse..\n",
    "print(X_train_bow[0]) # here we take a look at the non-zero elements. \n",
    "#The first element is the word with ID 25459, which appears two times in the text.\n",
    "print(vectorizer.get_feature_names()[13844]) # this is one way to get the word with the ID 25459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc3aaaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TF_IDF\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5279f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most similar: [  100 55483 57563 37648 11135 22220  4948  3379 23069 35121]\n",
      "least similar [ 2901 15920 34930 15907 34976 44921 53515 34989 52065]\n"
     ]
    }
   ],
   "source": [
    "cosine_similarities = cosine_similarity(X_train_tfidf[100], X_train_tfidf).flatten()\n",
    "\n",
    "indices = cosine_similarities.argsort()[::-1] # in descending order \n",
    "print(\"most similar:\",indices[:10])\n",
    "print(\"least similar\", indices[-9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c9a7def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professor Brinton was an amazing professor and really helped me through the class. He was readily available for questions and puts a lot of time into his courses. I would highly recommend him if you have the opportunity to take one of his classes.\n",
      "\n",
      "most similar:  Marcus was very helpful when i was confused.  Great teacher to have.\n",
      "\n",
      "least similar:  Great. Very well-read and informed. Brings a global perspective to his class which most Americans do not.\n"
     ]
    }
   ],
   "source": [
    "print(X_train[100])\n",
    "print()\n",
    "print(\"most similar: \", X_train[55483  ])\n",
    "print()\n",
    "print(\"least similar: \", X_train[2901  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52c0a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "X = df_c['Clean_comment']\n",
    "\n",
    "y = df_c['Quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=161193)\n",
    "\n",
    "\n",
    "# using the train_sents from earlier (the lowercased and tokenized sentences)\n",
    "model = Word2Vec(X_train, vector_size=50)#the default learning algorithm is CBOW. To use skip-gram use the paramter sg=1.\n",
    "\n",
    "# You can load pretrained embeddings downloaded from: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing \n",
    "# BUT this takes up a lot of space (the file is over 1 GB) and a lot of RAM when you try to use it.\n",
    "# If you want to try it, write this:\n",
    "#model = gensim.models.KeyedVectors.load_word2vec_format(directory_path+'GoogleNews-vectors-negative300.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2febb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3427301 ,  1.6213628 ,  0.18186499, -0.6462621 ,  0.19362907,\n",
       "       -1.1867796 ,  2.288043  , -0.22551453,  2.7086349 ,  0.43891525,\n",
       "        2.292423  , -0.9978531 ,  1.0667039 ,  0.7378389 ,  0.45770636,\n",
       "        1.1756386 ,  0.5812719 ,  0.38641572, -2.8912237 , -1.594051  ,\n",
       "        1.8976976 ,  0.00520311,  1.3018486 ,  0.22148238, -0.9200242 ,\n",
       "       -0.12997903,  1.2154835 ,  1.8347392 ,  0.01004102, -0.37225938,\n",
       "       -1.2753783 , -1.0325412 ,  1.5503664 , -0.51728296,  0.36603075,\n",
       "        0.7540513 ,  0.63373584, -0.46928576, -0.09215516,  2.1362817 ,\n",
       "        0.10410433, -0.05551953,  0.3986686 , -1.0420195 ,  2.4545798 ,\n",
       "       -0.7012055 , -0.49838266, -0.7577969 ,  0.7570233 ,  0.20809633],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['professor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "edb00ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reducing the 50-dimensional vectors to 2 dimensions in order to visualise selected words.\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "words = [\"test\",\"easy\", \"teacher\", \"ta\", \"bad\", \"horrible\", \"time\", \"expensive\", \"hot\", \"never\"]\n",
    "\n",
    "X = [model.wv['test'], model.wv['easy'], \n",
    "     model.wv['teacher'], model.wv['ta'], \n",
    "     model.wv['bad'], model.wv['horrible'], \n",
    "     model.wv['time'], model.wv['expensive'],\n",
    "     model.wv['hot'], model.wv['never']]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit(X).transform(X)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(X_r[:,0], X_r[:,1], edgecolors='k', c='r')\n",
    "for word, (x,y) in zip(words, X_r):\n",
    "    plt.text(x+0.2, y+0.1, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "258c72d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-84-a7855ecdb29a>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  embedded_text = np.array([np.mean([model.wv[w] if w in model.wv.key_to_index.keys() else np.zeros(50) for w in words], axis=0) for words in X_train])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-a7855ecdb29a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Using the averaged word2vec document embeddings to find similar documents:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcosine_similarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedded_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# in descending order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"most similar:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;31m# to avoid recursive import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    147\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                         estimator=estimator)\n\u001b[1;32m--> 149\u001b[1;33m         Y = check_array(Y, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[0m\u001b[0;32m    150\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                         estimator=estimator)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "###SE PÅ SENERE\n",
    "\n",
    "embedded_text = np.array([np.mean([model.wv[w] if w in model.wv.key_to_index.keys() else np.zeros(50) for w in words], axis=0) for words in X_train])\n",
    "\n",
    "\n",
    "# Using the averaged word2vec document embeddings to find similar documents:\n",
    "cosine_similarities = cosine_similarity(embedded_text[0].reshape(1,50), embedded_text[:]).flatten()\n",
    "indices = cosine_similarities.argsort()[::-1] # in descending order \n",
    "print(\"most similar:\",indices[:10])\n",
    "print(\"least similar\", indices[-9:])\n",
    "print(X_train[0])\n",
    "print()\n",
    "print(\"most similar: \", X_train[5052])\n",
    "print()\n",
    "print(\"least similar: \", X_train[22007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6939314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76872\n",
      "76872\n"
     ]
    }
   ],
   "source": [
    "y = np.where(df_c['Quality']>=3.5, 'good', 'bad')\n",
    "\n",
    "X = df_c['Comments']\n",
    "\n",
    "np.where(df_c['Quality']>=3.5, 'good', 'bad')\n",
    "   \n",
    "\n",
    "print(len(y))\n",
    "print(len(X))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=161193)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a70e47ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.8362646130363895\n",
      "testing accuracy: 0.8092933707982101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Get feature vectors\n",
    "tfidf = TfidfVectorizer()\n",
    "# use your own preprocessing function in the vectorizer when you've finished that exercise:\n",
    "#tfidf = TfidfVectorizer(tokenizer=preprocess)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# labels\n",
    "y_train = y_train\n",
    "y_test = y_test\n",
    "\n",
    "# classifier\n",
    "lr = LogisticRegression(random_state=0)\n",
    "\n",
    "#training\n",
    "lr.fit(X_train_tfidf,y_train)\n",
    "\n",
    "#testing\n",
    "train_preds = lr.predict(X_train_tfidf)\n",
    "test_preds = lr.predict(X_test_tfidf)\n",
    "print(\"training accuracy:\", np.mean([(train_preds==y_train)]))\n",
    "print(\"testing accuracy:\", np.mean([(test_preds==y_test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f0bcaef1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000001g</th>\n",
       "      <th>0006</th>\n",
       "      <th>001</th>\n",
       "      <th>0010</th>\n",
       "      <th>002</th>\n",
       "      <th>004</th>\n",
       "      <th>005</th>\n",
       "      <th>0072558318</th>\n",
       "      <th>...</th>\n",
       "      <th>ás</th>\n",
       "      <th>útil</th>\n",
       "      <th>ōlelo</th>\n",
       "      <th>ʻana</th>\n",
       "      <th>ʻike</th>\n",
       "      <th>ʻo</th>\n",
       "      <th>ʻoe</th>\n",
       "      <th>ʻoluʻolu</th>\n",
       "      <th>ʻoʻoleʻa</th>\n",
       "      <th>爸爸</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048164</td>\n",
       "      <td>-0.137459</td>\n",
       "      <td>-0.117054</td>\n",
       "      <td>-0.064267</td>\n",
       "      <td>-0.220373</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.020846</td>\n",
       "      <td>0.019865</td>\n",
       "      <td>0.081524</td>\n",
       "      <td>-0.111459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187838</td>\n",
       "      <td>0.072255</td>\n",
       "      <td>0.020433</td>\n",
       "      <td>0.045995</td>\n",
       "      <td>0.045995</td>\n",
       "      <td>0.091989</td>\n",
       "      <td>0.045995</td>\n",
       "      <td>0.045995</td>\n",
       "      <td>0.045995</td>\n",
       "      <td>0.140488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000   000001g      0006       001      0010       002  \\\n",
       "0  0.048164 -0.137459 -0.117054 -0.064267 -0.220373  0.084337  0.020846   \n",
       "\n",
       "        004       005  0072558318  ...        ás      útil     ōlelo  \\\n",
       "0  0.019865  0.081524   -0.111459  ...  0.187838  0.072255  0.020433   \n",
       "\n",
       "       ʻana      ʻike        ʻo       ʻoe  ʻoluʻolu  ʻoʻoleʻa        爸爸  \n",
       "0  0.045995  0.045995  0.091989  0.045995  0.045995  0.045995  0.140488  \n",
       "\n",
       "[1 rows x 28328 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['_'.join(s.split()) for s in tfidf.get_feature_names()]\n",
    "coefficients = lr.coef_\n",
    "coefs_df = pd.DataFrame.from_records(coefficients, columns=features)\n",
    "coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f65dc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0\n",
      "great         4.665930\n",
      "amazing       4.644933\n",
      "best          4.631600\n",
      "excellent     4.494046\n",
      "awesome       3.950368\n",
      "wonderful     3.724243\n",
      "helpful       3.477301\n",
      "loved         3.052912\n",
      "hilarious     2.875124\n",
      "fun           2.809272\n",
      "fantastic     2.733415\n",
      "highly        2.700198\n",
      "interesting   2.686381\n",
      "cool          2.684344\n",
      "explains      2.669693\n",
      "cares         2.561864\n",
      "rocks         2.544533\n",
      "favorite      2.536366\n",
      "easy          2.446267\n",
      "enthusiastic  2.414573\n",
      "\n",
      "                    0\n",
      "worst       -6.675677\n",
      "not         -5.295324\n",
      "avoid       -4.584834\n",
      "unclear     -4.035717\n",
      "horrible    -3.625365\n",
      "rude        -3.549601\n",
      "useless     -3.503210\n",
      "luck        -3.413324\n",
      "confusing   -3.302065\n",
      "terrible    -3.284915\n",
      "poor        -3.196714\n",
      "nothing     -3.061069\n",
      "awful       -2.933359\n",
      "unorganized -2.867737\n",
      "unhelpful   -2.847724\n",
      "doesn       -2.843693\n",
      "reads       -2.640829\n",
      "yourself    -2.564195\n",
      "thinks      -2.547505\n",
      "vague       -2.538503\n"
     ]
    }
   ],
   "source": [
    "print(coefs_df.T.sort_values(by=[0], ascending=False).head(20))\n",
    "print()\n",
    "print(coefs_df.T.sort_values(by=[0], ascending=True).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae8336",
   "metadata": {},
   "source": [
    "## De faktisk modeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "237bfd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = df_c[df_c['status']=='top']\n",
    "bottom = df_c[df_c['status']=='bottom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "99554eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top universities\n",
    "y_t = np.where(top['Quality']>=3.5, 'good', 'bad')\n",
    "\n",
    "X_t = top['Comments']\n",
    "\n",
    "Xt_train, Xt_test, yt_train, yt_test = train_test_split(X_t, y_t, random_state=161193)\n",
    "\n",
    "#bottom universities\n",
    "y_b = np.where(bottom['Quality']>=3.5, 'good', 'bad')\n",
    "\n",
    "X_b = bottom['Comments']\n",
    "\n",
    "Xb_train, Xb_test, yb_train, yb_test = train_test_split(X_b, y_b, random_state=161193)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e5eb479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.8742195827622963\n",
      "testing accuracy: 0.8348560986751942\n",
      "                     0\n",
      "great         4.665930\n",
      "amazing       4.644933\n",
      "best          4.631600\n",
      "excellent     4.494046\n",
      "awesome       3.950368\n",
      "wonderful     3.724243\n",
      "helpful       3.477301\n",
      "loved         3.052912\n",
      "hilarious     2.875124\n",
      "fun           2.809272\n",
      "fantastic     2.733415\n",
      "highly        2.700198\n",
      "interesting   2.686381\n",
      "cool          2.684344\n",
      "explains      2.669693\n",
      "cares         2.561864\n",
      "rocks         2.544533\n",
      "favorite      2.536366\n",
      "easy          2.446267\n",
      "enthusiastic  2.414573\n",
      "\n",
      "                    0\n",
      "worst       -6.675677\n",
      "not         -5.295324\n",
      "avoid       -4.584834\n",
      "unclear     -4.035717\n",
      "horrible    -3.625365\n",
      "rude        -3.549601\n",
      "useless     -3.503210\n",
      "luck        -3.413324\n",
      "confusing   -3.302065\n",
      "terrible    -3.284915\n",
      "poor        -3.196714\n",
      "nothing     -3.061069\n",
      "awful       -2.933359\n",
      "unorganized -2.867737\n",
      "unhelpful   -2.847724\n",
      "doesn       -2.843693\n",
      "reads       -2.640829\n",
      "yourself    -2.564195\n",
      "thinks      -2.547505\n",
      "vague       -2.538503\n"
     ]
    }
   ],
   "source": [
    "# Get feature vectors\n",
    "tfidf = TfidfVectorizer()\n",
    "# use your own preprocessing function in the vectorizer when you've finished that exercise:\n",
    "#tfidf = TfidfVectorizer(tokenizer=preprocess)\n",
    "Xt_train_tfidf = tfidf.fit_transform(Xt_train)\n",
    "Xt_test_tfidf = tfidf.transform(Xt_test)\n",
    "\n",
    "# labels\n",
    "yt_train = yt_train\n",
    "yt_test = yt_test\n",
    "\n",
    "# classifier\n",
    "lr = LogisticRegression(random_state=0)\n",
    "\n",
    "#training\n",
    "lr.fit(Xt_train_tfidf,yt_train)\n",
    "\n",
    "#testing\n",
    "ttrain_preds = lr.predict(Xt_train_tfidf)\n",
    "ttest_preds = lr.predict(Xt_test_tfidf)\n",
    "print(\"training accuracy:\", np.mean([(ttrain_preds==yt_train)]))\n",
    "print(\"testing accuracy:\", np.mean([(ttest_preds==yt_test)]))\n",
    "\n",
    "print(coefs_df.T.sort_values(by=[0], ascending=False).head(20))\n",
    "print()\n",
    "print(coefs_df.T.sort_values(by=[0], ascending=True).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ce6d43a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>001</th>\n",
       "      <th>0010</th>\n",
       "      <th>004</th>\n",
       "      <th>0072558318</th>\n",
       "      <th>00am</th>\n",
       "      <th>01</th>\n",
       "      <th>012</th>\n",
       "      <th>014</th>\n",
       "      <th>...</th>\n",
       "      <th>zschau</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zumhagen</th>\n",
       "      <th>zwi</th>\n",
       "      <th>zwrite</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzz</th>\n",
       "      <th>útil</th>\n",
       "      <th>爸爸</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.034831</td>\n",
       "      <td>0.105375</td>\n",
       "      <td>-0.161263</td>\n",
       "      <td>0.08907</td>\n",
       "      <td>0.016494</td>\n",
       "      <td>-0.125748</td>\n",
       "      <td>0.083103</td>\n",
       "      <td>-0.208883</td>\n",
       "      <td>0.021966</td>\n",
       "      <td>-0.17457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089757</td>\n",
       "      <td>-0.276969</td>\n",
       "      <td>-0.112182</td>\n",
       "      <td>0.030639</td>\n",
       "      <td>0.105531</td>\n",
       "      <td>-0.132853</td>\n",
       "      <td>-0.252413</td>\n",
       "      <td>-0.055328</td>\n",
       "      <td>0.081649</td>\n",
       "      <td>0.1747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 14644 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000       001     0010       004  0072558318      00am  \\\n",
       "0 -0.034831  0.105375 -0.161263  0.08907  0.016494   -0.125748  0.083103   \n",
       "\n",
       "         01       012      014  ...    zschau    zucker  zumhagen       zwi  \\\n",
       "0 -0.208883  0.021966 -0.17457  ...  0.089757 -0.276969 -0.112182  0.030639   \n",
       "\n",
       "     zwrite        zz       zzz      zzzz      útil      爸爸  \n",
       "0  0.105531 -0.132853 -0.252413 -0.055328  0.081649  0.1747  \n",
       "\n",
       "[1 rows x 14644 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['_'.join(s.split()) for s in tfidf.get_feature_names()]\n",
    "coefficients = lr.coef_\n",
    "coefs_df = pd.DataFrame.from_records(coefficients, columns=features)\n",
    "coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "78b7782f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0\n",
      "best       4.550059\n",
      "amazing    4.030124\n",
      "great      3.944210\n",
      "excellent  3.415934\n",
      "awesome    3.102986\n",
      "wonderful  2.721556\n",
      "loved      2.646081\n",
      "always     2.541157\n",
      "fantastic  2.474019\n",
      "love       2.444734\n",
      "brilliant  2.424629\n",
      "helpful    2.406449\n",
      "explains   2.336687\n",
      "highly     2.276719\n",
      "willing    2.181848\n",
      "cares      2.173476\n",
      "cool       2.133345\n",
      "sure       1.929296\n",
      "good       1.927644\n",
      "clear      1.898594\n",
      "\n",
      "                     0\n",
      "worst        -6.463011\n",
      "not          -5.909493\n",
      "terrible     -3.902084\n",
      "horrible     -3.753817\n",
      "unclear      -3.414217\n",
      "avoid        -3.110569\n",
      "no           -2.929982\n",
      "rude         -2.792904\n",
      "useless      -2.704012\n",
      "doesn        -2.635714\n",
      "thinks       -2.546257\n",
      "poor         -2.484423\n",
      "unhelpful    -2.437398\n",
      "confusing    -2.309770\n",
      "himself      -2.258127\n",
      "luck         -2.213404\n",
      "awful        -2.149665\n",
      "don          -2.147540\n",
      "disorganized -2.131567\n",
      "seems        -2.030893\n"
     ]
    }
   ],
   "source": [
    "print(coefs_df.T.sort_values(by=[0], ascending=False).head(20))\n",
    "print()\n",
    "print(coefs_df.T.sort_values(by=[0], ascending=True).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "75a9da3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.8309973045822102\n",
      "testing accuracy: 0.7981805929919138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Get feature vectors\n",
    "tfidf = TfidfVectorizer()\n",
    "# use your own preprocessing function in the vectorizer when you've finished that exercise:\n",
    "#tfidf = TfidfVectorizer(tokenizer=preprocess)\n",
    "Xb_train_tfidf = tfidf.fit_transform(Xb_train)\n",
    "Xb_test_tfidf = tfidf.transform(Xb_test)\n",
    "\n",
    "# labels\n",
    "yb_train = yb_train\n",
    "yb_test = yb_test\n",
    "\n",
    "# classifier\n",
    "lr = LogisticRegression(random_state=0)\n",
    "\n",
    "#training\n",
    "lr.fit(Xb_train_tfidf,yb_train)\n",
    "\n",
    "#testing\n",
    "train_preds = lr.predict(Xb_train_tfidf)\n",
    "test_preds = lr.predict(Xb_test_tfidf)\n",
    "print(\"training accuracy:\", np.mean([(train_preds==yb_train)]))\n",
    "print(\"testing accuracy:\", np.mean([(test_preds==yb_test)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4f16309f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000001g</th>\n",
       "      <th>0006</th>\n",
       "      <th>001</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>011</th>\n",
       "      <th>012</th>\n",
       "      <th>...</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>álvarez</th>\n",
       "      <th>ás</th>\n",
       "      <th>ōlelo</th>\n",
       "      <th>ʻana</th>\n",
       "      <th>ʻike</th>\n",
       "      <th>ʻo</th>\n",
       "      <th>ʻoe</th>\n",
       "      <th>ʻoluʻolu</th>\n",
       "      <th>ʻoʻoleʻa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.153968</td>\n",
       "      <td>-0.652141</td>\n",
       "      <td>-0.117905</td>\n",
       "      <td>-0.068689</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>-0.098886</td>\n",
       "      <td>0.119629</td>\n",
       "      <td>-0.273118</td>\n",
       "      <td>0.077714</td>\n",
       "      <td>0.077714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311484</td>\n",
       "      <td>0.175997</td>\n",
       "      <td>0.186505</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.043434</td>\n",
       "      <td>0.043434</td>\n",
       "      <td>0.086868</td>\n",
       "      <td>0.043434</td>\n",
       "      <td>0.043434</td>\n",
       "      <td>0.043434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000   000001g      0006       001      00am      00pm  \\\n",
       "0 -0.153968 -0.652141 -0.117905 -0.068689  0.041939 -0.098886  0.119629   \n",
       "\n",
       "         01       011       012  ...  zzzzzzzzzzzzzzzzzzzzzz   álvarez  \\\n",
       "0 -0.273118  0.077714  0.077714  ...               -0.311484  0.175997   \n",
       "\n",
       "         ás     ōlelo      ʻana      ʻike        ʻo       ʻoe  ʻoluʻolu  \\\n",
       "0  0.186505  0.020482  0.043434  0.043434  0.086868  0.043434  0.043434   \n",
       "\n",
       "   ʻoʻoleʻa  \n",
       "0  0.043434  \n",
       "\n",
       "[1 rows x 23113 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['_'.join(s.split()) for s in tfidf.get_feature_names()]\n",
    "coefficients = lr.coef_\n",
    "coefs_df = pd.DataFrame.from_records(coefficients, columns=features)\n",
    "coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7d826e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0\n",
      "great        5.166606\n",
      "best         4.433569\n",
      "awesome      4.165015\n",
      "amazing      3.978236\n",
      "excellent    3.808891\n",
      "helpful      3.583302\n",
      "fun          3.354404\n",
      "wonderful    3.218319\n",
      "interesting  2.869070\n",
      "hilarious    2.845134\n",
      "easy         2.829384\n",
      "loved        2.741220\n",
      "cool         2.438599\n",
      "you          2.332321\n",
      "highly       2.320102\n",
      "cares        2.227371\n",
      "love         2.207271\n",
      "enjoyable    2.188529\n",
      "attention    2.125369\n",
      "favorite     2.070249\n",
      "\n",
      "                    0\n",
      "worst       -5.966652\n",
      "not         -5.182568\n",
      "avoid       -4.523254\n",
      "unclear     -4.076124\n",
      "rude        -3.783279\n",
      "horrible    -3.416215\n",
      "luck        -3.343650\n",
      "unorganized -3.159193\n",
      "reads       -3.144532\n",
      "useless     -3.055804\n",
      "nothing     -3.039199\n",
      "confusing   -3.018885\n",
      "terrible    -2.733022\n",
      "doesn       -2.620068\n",
      "awful       -2.575519\n",
      "unhelpful   -2.438693\n",
      "yourself    -2.377456\n",
      "no          -2.351225\n",
      "sucks       -2.273980\n",
      "never       -2.245244\n"
     ]
    }
   ],
   "source": [
    "print(coefs_df.T.sort_values(by=[0], ascending=False).head(20))\n",
    "print()\n",
    "print(coefs_df.T.sort_values(by=[0], ascending=True).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a094e3",
   "metadata": {},
   "source": [
    "## TOP OR BOTTOM???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f93565e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bottom universities\n",
    "y= df_c['status']\n",
    "\n",
    "X = df_c['Comments']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=161193)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9d3fcb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.8449717278939882\n",
      "testing accuracy: 0.8147569986471017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Get feature vectors\n",
    "tfidf = TfidfVectorizer()\n",
    "# use your own preprocessing function in the vectorizer when you've finished that exercise:\n",
    "#tfidf = TfidfVectorizer(tokenizer=preprocess)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# labels\n",
    "y_train = y_train\n",
    "y_test = y_test\n",
    "\n",
    "# classifier\n",
    "lr = LogisticRegression(random_state=0)\n",
    "\n",
    "#training\n",
    "lr.fit(X_train_tfidf,y_train)\n",
    "\n",
    "#testing\n",
    "train_preds = lr.predict(X_train_tfidf)\n",
    "test_preds = lr.predict(X_test_tfidf)\n",
    "print(\"training accuracy:\", np.mean([(train_preds==y_train)]))\n",
    "print(\"testing accuracy:\", np.mean([(test_preds==y_test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6f4e0f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000001g</th>\n",
       "      <th>0006</th>\n",
       "      <th>001</th>\n",
       "      <th>0010</th>\n",
       "      <th>002</th>\n",
       "      <th>004</th>\n",
       "      <th>005</th>\n",
       "      <th>0072558318</th>\n",
       "      <th>...</th>\n",
       "      <th>ás</th>\n",
       "      <th>útil</th>\n",
       "      <th>ōlelo</th>\n",
       "      <th>ʻana</th>\n",
       "      <th>ʻike</th>\n",
       "      <th>ʻo</th>\n",
       "      <th>ʻoe</th>\n",
       "      <th>ʻoluʻolu</th>\n",
       "      <th>ʻoʻoleʻa</th>\n",
       "      <th>爸爸</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.046048</td>\n",
       "      <td>-0.127897</td>\n",
       "      <td>-0.03474</td>\n",
       "      <td>-0.032946</td>\n",
       "      <td>0.200457</td>\n",
       "      <td>0.144476</td>\n",
       "      <td>0.258954</td>\n",
       "      <td>0.141007</td>\n",
       "      <td>0.34441</td>\n",
       "      <td>0.222986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026197</td>\n",
       "      <td>0.098113</td>\n",
       "      <td>-0.069256</td>\n",
       "      <td>-0.059663</td>\n",
       "      <td>-0.059663</td>\n",
       "      <td>-0.119326</td>\n",
       "      <td>-0.059663</td>\n",
       "      <td>-0.059663</td>\n",
       "      <td>-0.059663</td>\n",
       "      <td>0.218622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000  000001g      0006       001      0010       002  \\\n",
       "0 -0.046048 -0.127897 -0.03474 -0.032946  0.200457  0.144476  0.258954   \n",
       "\n",
       "        004      005  0072558318  ...        ás      útil     ōlelo      ʻana  \\\n",
       "0  0.141007  0.34441    0.222986  ... -0.026197  0.098113 -0.069256 -0.059663   \n",
       "\n",
       "       ʻike        ʻo       ʻoe  ʻoluʻolu  ʻoʻoleʻa        爸爸  \n",
       "0 -0.059663 -0.119326 -0.059663 -0.059663 -0.059663  0.218622  \n",
       "\n",
       "[1 rows x 28328 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['_'.join(s.split()) for s in tfidf.get_feature_names()]\n",
    "coefficients = lr.coef_\n",
    "coefs_df = pd.DataFrame.from_records(coefficients, columns=features)\n",
    "coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a810f71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0\n",
      "cal           8.862269\n",
      "hopkins       7.079086\n",
      "columbia      5.545774\n",
      "calu          5.183457\n",
      "stanford      4.958527\n",
      "harvard       4.454993\n",
      "lecturer      4.396760\n",
      "yale          4.328290\n",
      "mit           4.202019\n",
      "jhu           4.178739\n",
      "tas           3.952823\n",
      "bonus         3.819250\n",
      "d2l           3.627678\n",
      "princeton     3.347357\n",
      "seminar       3.338100\n",
      "brilliant     3.329057\n",
      "sets          3.128428\n",
      "orgo          3.086214\n",
      "midterms      2.976965\n",
      "zisk          2.760191\n",
      "nelson        2.749731\n",
      "china         2.714091\n",
      "ideas         2.660651\n",
      "mcgukin       2.572575\n",
      "engaging      2.492497\n",
      "quarter       2.469868\n",
      "18            2.461260\n",
      "landy         2.368452\n",
      "ta            2.275671\n",
      "sweitzer      2.249404\n",
      "policy        2.230159\n",
      "batteh        2.224304\n",
      "neuroscience  2.174923\n",
      "hours         2.166339\n",
      "slaven        2.136353\n",
      "hess          2.134556\n",
      "social        2.048230\n",
      "rewarding     2.015622\n",
      "backtests     2.002659\n",
      "incredibly    1.991141\n",
      "\n",
      "                      0\n",
      "csu           -6.793768\n",
      "wsu           -5.322216\n",
      "wku           -4.941742\n",
      "twu           -4.270279\n",
      "regent        -3.502346\n",
      "pba           -3.481070\n",
      "dr            -3.159216\n",
      "test          -2.998854\n",
      "ms            -2.994659\n",
      "mrs           -2.972945\n",
      "expectations  -2.908665\n",
      "mr            -2.881023\n",
      "pass          -2.811383\n",
      "quizzes       -2.684472\n",
      "reviews       -2.586600\n",
      "credit        -2.569885\n",
      "cleveland     -2.542338\n",
      "tests         -2.530455\n",
      "chapter       -2.424614\n",
      "grades        -2.382137\n",
      "boards        -2.378782\n",
      "semester      -2.347688\n",
      "yourself      -2.333798\n",
      "wichita       -2.313192\n",
      "western       -2.234057\n",
      "homework      -2.228454\n",
      "communication -2.204230\n",
      "instructor    -2.195811\n",
      "blackboard    -2.189943\n",
      "teacher       -2.153310\n",
      "si            -2.151698\n",
      "expects       -2.080921\n",
      "tyler         -2.064698\n",
      "state         -2.062858\n",
      "instructions  -2.060408\n",
      "passed        -1.995099\n",
      "succeed       -1.992546\n",
      "content       -1.983001\n",
      "extra         -1.967910\n",
      "relatable     -1.899909\n"
     ]
    }
   ],
   "source": [
    "print(coefs_df.T.sort_values(by=[0], ascending=False).head(40))\n",
    "print()\n",
    "print(coefs_df.T.sort_values(by=[0], ascending=True).head(40))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
