{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6cfcb7c",
   "metadata": {},
   "source": [
    "## Regressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c8ce43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Liv\n",
      "[nltk_data]     Nøhr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Liv\n",
      "[nltk_data]     Nøhr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Liv\n",
      "[nltk_data]     Nøhr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## load packages\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "#SKLEARN\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for vectorization \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#For word handeling\n",
    "import string \n",
    "import nltk\n",
    "nltk.download('punkt') # you will probably need to do this\n",
    "nltk.download('wordnet') # and this\n",
    "nltk.download('stopwords') # aand this\n",
    "\n",
    "# for classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fcc42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    low_text= text.lower()\n",
    "    low_text = low_text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(low_text)\n",
    "    porter = nltk.WordNetLemmatizer()\n",
    "    lemmatizer=[porter.lemmatize(t) for t in tokens]\n",
    "    stop_words_list = stoppelop\n",
    "    sent_sw_removed = [i for i in lemmatizer if i not in stop_words_list]\n",
    "    lemmas=[i for i in sent_sw_removed if i!='br']\n",
    "    return lemmas # return a list of stems/lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89119c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70307    She is rude and she hardly really taught the c...\n",
      "32222    i am in class right now..i would honestly rath...\n",
      "41925    Dr. Jack Thacker is the best professor you wil...\n",
      "41720    Multiple Tegrity lecture recordings that were ...\n",
      "32150                                Avoid this professor.\n",
      "                               ...                        \n",
      "47433    He is a great teacher and cares for his studen...\n",
      "55647    Professor Kan does not give exams other than t...\n",
      "40374    Rich makes you work, but was really helpful ou...\n",
      "18837    Dr. Wang  was well prepared for class, and tau...\n",
      "2852                   Not very friendly for office hours.\n",
      "Name: Comments, Length: 57654, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Get data\n",
    "df_c = pd.read_csv('df_comments_final.csv')\n",
    "df_c = df_c.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "df_c=df_c[df_c['Comments']!='No Comments']\n",
    "\n",
    "df_c['year'] = df_c['Dates'].str[2:4]\n",
    "\n",
    "#Divide into target and features\n",
    "y= df_c['status']\n",
    "\n",
    "X = df_c['Comments']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=161193)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82632712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cal',\n",
       " 'calu',\n",
       " 'jhu',\n",
       " 'mit',\n",
       " 'orgo',\n",
       " 'pwr',\n",
       " 'uchicago',\n",
       " 'cussw',\n",
       " 'ssa',\n",
       " 'csu',\n",
       " 'wsu',\n",
       " 'wku',\n",
       " 'twu',\n",
       " 'pba',\n",
       " 'ut',\n",
       " 'utt',\n",
       " 'uhh',\n",
       " 'asl',\n",
       " 'nan',\n",
       " 'gamm',\n",
       " 'york',\n",
       " 'berlin',\n",
       " 'ray',\n",
       " 'pat',\n",
       " 'simpser',\n",
       " 'beck',\n",
       " 'toscano',\n",
       " 'ochs',\n",
       " 'rodriguezjimenez',\n",
       " 'pruitt',\n",
       " 'shaunna',\n",
       " 'kirven',\n",
       " 'susannah',\n",
       " 'robbins',\n",
       " 'ryan',\n",
       " 'shakti',\n",
       " 'ronchen',\n",
       " 'neenan',\n",
       " 'bob',\n",
       " 'mcelvy',\n",
       " 'salari',\n",
       " 'malkin',\n",
       " 'ebach',\n",
       " 'samuel',\n",
       " 'lava',\n",
       " 'guerrero',\n",
       " 'leanna',\n",
       " 'linehan',\n",
       " 'merenda',\n",
       " 'sanaz',\n",
       " 'rorabaugh',\n",
       " 'neely',\n",
       " 'shannan',\n",
       " 'carfango',\n",
       " 'embertontinus',\n",
       " 'benshahar',\n",
       " 'noam',\n",
       " 'atkinson',\n",
       " 'gorski',\n",
       " 'nahee',\n",
       " 'liisa',\n",
       " 'lasley',\n",
       " 'vega',\n",
       " 'keat',\n",
       " 'hallie',\n",
       " 'madsen',\n",
       " 'bukonda',\n",
       " 'andrew',\n",
       " 'ze',\n",
       " 'joonhyun',\n",
       " 'hoffmann',\n",
       " 'laurentsimpson',\n",
       " 'mccabe',\n",
       " 'wei',\n",
       " 'planning',\n",
       " 'public',\n",
       " 'policy',\n",
       " 'janis',\n",
       " 'chertow',\n",
       " 'mabel',\n",
       " 'karem',\n",
       " 'rundell',\n",
       " 'noble',\n",
       " 'willome',\n",
       " 'brittnee',\n",
       " 'movassaghi',\n",
       " 'creasy',\n",
       " 'juneau',\n",
       " 'preslan',\n",
       " 'grice',\n",
       " 'sijie',\n",
       " 'hebron',\n",
       " 'sang',\n",
       " 'golnaz',\n",
       " 'khalafallah',\n",
       " 'gomez',\n",
       " 'trump',\n",
       " 'hardy',\n",
       " 'pavlos',\n",
       " 'aishwary',\n",
       " 'shigehisa',\n",
       " 'oleg',\n",
       " 'hinkie',\n",
       " 'belt',\n",
       " 'morgiana',\n",
       " 'kitchloo',\n",
       " 'bednar',\n",
       " 'klein',\n",
       " 'stocker',\n",
       " 'natasha',\n",
       " 'sanatullov',\n",
       " 'carlos',\n",
       " 'rolf',\n",
       " 'hazel',\n",
       " 'miranda',\n",
       " 'carson',\n",
       " 'enlow',\n",
       " 'roberta',\n",
       " 'stormsmith',\n",
       " 'burton',\n",
       " 'bilgrami',\n",
       " 'boff',\n",
       " 'namboodiri',\n",
       " 'bearden',\n",
       " 'coyne',\n",
       " 'kapugamage',\n",
       " 'drehr',\n",
       " 'bettersworth',\n",
       " 'willoughby',\n",
       " 'jaroslav',\n",
       " 'jeannette',\n",
       " 'christel',\n",
       " 'sanza',\n",
       " 'boggess',\n",
       " 'benjamin',\n",
       " 'hyuck',\n",
       " 'muhchung',\n",
       " 'vargas',\n",
       " 'saurov',\n",
       " 'eichhorn',\n",
       " 'konte',\n",
       " 'kober',\n",
       " 'arguelles',\n",
       " 'meg',\n",
       " 'aimin',\n",
       " 'elliot',\n",
       " 'haeseung',\n",
       " 'chesko',\n",
       " 'tate',\n",
       " 'wainer',\n",
       " 'saeed',\n",
       " 'judith',\n",
       " 'brenda',\n",
       " 'rylander',\n",
       " 'gatica',\n",
       " 'farhan',\n",
       " 'kausel',\n",
       " 'maple',\n",
       " 'kamel',\n",
       " 'ramsey',\n",
       " 'kosaraju',\n",
       " 'aranovskaya',\n",
       " 'holli',\n",
       " 'n',\n",
       " 'durning',\n",
       " 'asmatulu',\n",
       " 'winchester',\n",
       " 'auslander',\n",
       " 'mcgill',\n",
       " 'rourke',\n",
       " 'sestanovich',\n",
       " 'nutrition',\n",
       " 'food',\n",
       " 'macey',\n",
       " 'gresnick',\n",
       " 'mclaughlin',\n",
       " 'leigh',\n",
       " 'mahiri',\n",
       " 'levene',\n",
       " 'silvatrujillo',\n",
       " 'mejia',\n",
       " 'alatorre',\n",
       " 'shattuck',\n",
       " 'lakshmikanth',\n",
       " 'mara',\n",
       " 'joy',\n",
       " 'pla',\n",
       " 'sack',\n",
       " 'lubos',\n",
       " 'yanbei',\n",
       " 'ondik',\n",
       " 'hock',\n",
       " 'franklin',\n",
       " 'kardar',\n",
       " 'hilpert',\n",
       " 'osh',\n",
       " 'kropf',\n",
       " 'saleh',\n",
       " 'ness',\n",
       " 'sour',\n",
       " 'favia',\n",
       " 'jayson',\n",
       " 'wild',\n",
       " 'hendrix',\n",
       " 'cayla',\n",
       " 'thatcher',\n",
       " 'ulrich',\n",
       " 'epley',\n",
       " 'busl',\n",
       " 'deuby',\n",
       " 'marci',\n",
       " 'dylliacco',\n",
       " 'gabriele',\n",
       " 'peelen',\n",
       " 'kellye',\n",
       " 'arflack',\n",
       " 'mckinley',\n",
       " 'scarry',\n",
       " 'mantovan',\n",
       " 'niro',\n",
       " 'korie',\n",
       " 'daniela',\n",
       " 'crist',\n",
       " 'foner',\n",
       " 'muehlstein',\n",
       " 'raejean',\n",
       " 'shajaat',\n",
       " 'sophia',\n",
       " 'watkins',\n",
       " 'conn',\n",
       " 'wu',\n",
       " 'aragon',\n",
       " 'dundee',\n",
       " 'shukula',\n",
       " 'chuck',\n",
       " 'mccarney',\n",
       " 'osullivan',\n",
       " 'papa',\n",
       " 'dalessio',\n",
       " 'olive',\n",
       " 'schopf',\n",
       " 'starkman',\n",
       " 'boller',\n",
       " 'dr',\n",
       " 'r',\n",
       " 'victoria',\n",
       " 'zhonghang',\n",
       " 'markin',\n",
       " 'craig',\n",
       " 'richmond',\n",
       " 'purdievaughn',\n",
       " 'brower',\n",
       " 'rania',\n",
       " 'twomey',\n",
       " 'teni',\n",
       " 'michaela',\n",
       " 'perkins',\n",
       " 'nana',\n",
       " 'darik',\n",
       " 'leiker',\n",
       " 'urbine',\n",
       " 'moy',\n",
       " 'mead',\n",
       " 'gorla',\n",
       " 'lynette',\n",
       " 'klausner',\n",
       " 'caudy',\n",
       " 'conte',\n",
       " 'kathleen',\n",
       " 'day',\n",
       " 'mahr',\n",
       " 'lindenmeyer',\n",
       " 'raoof',\n",
       " 'yates',\n",
       " 'sipser',\n",
       " 'ru',\n",
       " 'cramerroh',\n",
       " 'brauch',\n",
       " 'vanderberg',\n",
       " 'orden',\n",
       " 'un',\n",
       " 'siegrist',\n",
       " 'wise',\n",
       " 'abishek',\n",
       " 'hank',\n",
       " 'lamprecht',\n",
       " 'reho',\n",
       " 'tan',\n",
       " 'jesse',\n",
       " 'counseling',\n",
       " 'guerrette',\n",
       " 'shroff',\n",
       " 'krieg',\n",
       " 'mira',\n",
       " 'helpman',\n",
       " 'autor',\n",
       " 'engineering',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'nikolaev',\n",
       " 'mullen',\n",
       " 'anthony',\n",
       " 'yassa',\n",
       " 'ayotte',\n",
       " 'alvarado',\n",
       " 'appleby',\n",
       " 'shelley',\n",
       " 'roundhill',\n",
       " 'reber',\n",
       " 'chriss',\n",
       " 'antsos',\n",
       " 'isanass',\n",
       " 'eliezer',\n",
       " 'hearn',\n",
       " 'zhang',\n",
       " 'newman',\n",
       " 'felstiner',\n",
       " 'marrar',\n",
       " 'ovella',\n",
       " 'nayar',\n",
       " 'cassill',\n",
       " 'olatokunbo',\n",
       " 'scholz',\n",
       " 'deedra',\n",
       " 'spedaliere',\n",
       " 'lanigan',\n",
       " 'leeroy',\n",
       " 'dance',\n",
       " 'wasser',\n",
       " 'houssein',\n",
       " 'ballout',\n",
       " 'learning',\n",
       " 'shermila',\n",
       " 'savizky',\n",
       " 'olsen',\n",
       " 'papana',\n",
       " 'roncagli',\n",
       " 'njoku',\n",
       " 'arpadi',\n",
       " 'frick',\n",
       " 'latora',\n",
       " 'handman',\n",
       " 'straight',\n",
       " 'flower',\n",
       " 'lipson',\n",
       " 'gitai',\n",
       " 'beam',\n",
       " 'babbit',\n",
       " 'triet',\n",
       " 'karbhari',\n",
       " 'rafe',\n",
       " 'roys',\n",
       " 'matlou',\n",
       " 'gayanthi',\n",
       " 'stefanie',\n",
       " 'bean',\n",
       " 'strode',\n",
       " 'siyu',\n",
       " 'neta',\n",
       " 'donoghue',\n",
       " 'schinke',\n",
       " 'yelverton',\n",
       " 'ashleigh',\n",
       " 'darwin',\n",
       " 'serafini',\n",
       " 'coelho',\n",
       " 'razumicrushin',\n",
       " 'knoblauch',\n",
       " 'pinkston',\n",
       " 'seiler',\n",
       " 'florea',\n",
       " 'burt',\n",
       " 'kohns',\n",
       " 'cheri',\n",
       " 'burant',\n",
       " 'reg',\n",
       " 'ekins',\n",
       " 'alamo',\n",
       " 'lozada',\n",
       " 'dzuong',\n",
       " 'duncan',\n",
       " 'carl',\n",
       " 'krishna',\n",
       " 'mohan',\n",
       " 'mccandliss',\n",
       " 'precht',\n",
       " 'prather',\n",
       " 'broberg',\n",
       " 'plank',\n",
       " 'combest',\n",
       " 'yaser',\n",
       " 'agatha',\n",
       " 'farber',\n",
       " 'viskocil',\n",
       " 'socrate',\n",
       " 'skorikov',\n",
       " 'delparte',\n",
       " 'toby',\n",
       " 'bruna',\n",
       " 'juliano',\n",
       " 'besio',\n",
       " 'vogeltaylor',\n",
       " 'lattie',\n",
       " 'zwierlein',\n",
       " 'pait',\n",
       " 'yuko',\n",
       " 'marilee',\n",
       " 'cyndi',\n",
       " 'water',\n",
       " 'prakup',\n",
       " 'devadas',\n",
       " 'doug',\n",
       " 'sigurd',\n",
       " 'ellinger',\n",
       " 'guclu',\n",
       " 'bruck',\n",
       " 'aquilanti',\n",
       " 'tebbitt',\n",
       " 'sire',\n",
       " 'scheinfeld',\n",
       " 'pincus',\n",
       " 'sturgell',\n",
       " 'polyanskiy',\n",
       " 'poonen',\n",
       " 'branham',\n",
       " 'lukun',\n",
       " 'savita',\n",
       " 'engber',\n",
       " 'meyers',\n",
       " 'cagney',\n",
       " 'linian',\n",
       " 'lecomte',\n",
       " 'diller',\n",
       " 'kulkarni',\n",
       " 'signoretti',\n",
       " 'bolt',\n",
       " 'fung',\n",
       " 'housewright',\n",
       " 'francois',\n",
       " 'gamal',\n",
       " 'bookshar',\n",
       " 'jasko',\n",
       " 'neda',\n",
       " 'steiner',\n",
       " 'barahona',\n",
       " 'chelley',\n",
       " 'placyk',\n",
       " 'gordan',\n",
       " 'mears',\n",
       " 'huabo',\n",
       " 'francesco',\n",
       " 'amelia',\n",
       " 'natt',\n",
       " 'lodhi',\n",
       " 'petru',\n",
       " 'mayta',\n",
       " 'helios',\n",
       " 'mauro',\n",
       " 'khurana',\n",
       " 'ohood',\n",
       " 'management',\n",
       " 'bowman',\n",
       " 'kiss',\n",
       " 'murad',\n",
       " 'minnitt',\n",
       " 'schreiber',\n",
       " 'ari',\n",
       " 'fanning',\n",
       " 'rehman',\n",
       " 'elkies',\n",
       " 'moudrianakis',\n",
       " 'takacs',\n",
       " 'deusenphillips',\n",
       " 'eiben',\n",
       " 'magda',\n",
       " 'parnam',\n",
       " 'marcella',\n",
       " 'new',\n",
       " 'comiskey',\n",
       " 'koch',\n",
       " 'whitney',\n",
       " 'dam',\n",
       " 'bayly',\n",
       " 'jhonny',\n",
       " 'braasch',\n",
       " 'petty',\n",
       " 'goodrich',\n",
       " 'marcee',\n",
       " 'mulac',\n",
       " 'larry',\n",
       " 'eugene',\n",
       " 'davood',\n",
       " 'adeola',\n",
       " 'janow',\n",
       " 'palla',\n",
       " 'delk',\n",
       " 'gordin',\n",
       " 'boukaabar',\n",
       " 'lepore',\n",
       " 'goldman',\n",
       " 'wechsler',\n",
       " 'gyan',\n",
       " 'rajeswari',\n",
       " 'enzo',\n",
       " 'umit',\n",
       " 'harkins',\n",
       " 'galauner',\n",
       " 'sunita',\n",
       " 'boehme',\n",
       " 'cipolla',\n",
       " 'bravman',\n",
       " 'jung',\n",
       " 'jenelle',\n",
       " 'littlejohn',\n",
       " 'counseling',\n",
       " 'student',\n",
       " 'affair',\n",
       " 'eagleman',\n",
       " 'adina',\n",
       " 'kinnison',\n",
       " 'maria',\n",
       " 'horowitz',\n",
       " 'jim',\n",
       " 'erickson',\n",
       " 'bosso',\n",
       " 'moran',\n",
       " 'quattlebaum',\n",
       " 'molly',\n",
       " 'spencer',\n",
       " 'turso',\n",
       " 'rhys',\n",
       " 'hota',\n",
       " 'napolitano',\n",
       " 'feinstein',\n",
       " 'obrenovich',\n",
       " 'zwiebach',\n",
       " 'lemke',\n",
       " 'sagers',\n",
       " 'deana',\n",
       " 'gaitely',\n",
       " 'thrash',\n",
       " 'benatar',\n",
       " 'adarose',\n",
       " 'sayjal',\n",
       " 'lene',\n",
       " 'shanda',\n",
       " 'dencil',\n",
       " 'xi',\n",
       " 'finch',\n",
       " 'videgaray',\n",
       " 'leopoldo',\n",
       " 'haysman',\n",
       " 'cervantez',\n",
       " 'roller',\n",
       " 'kliment',\n",
       " 'han',\n",
       " 'alla',\n",
       " 'addie',\n",
       " 'fangpei',\n",
       " 'teardo',\n",
       " 'myongho',\n",
       " 'radzilowicz',\n",
       " 'corkern',\n",
       " 'thomason',\n",
       " 'kholil',\n",
       " 'majette',\n",
       " 'sundip',\n",
       " 'ta',\n",
       " 'niederriter',\n",
       " 'kwame',\n",
       " 'lilian',\n",
       " 'washing',\n",
       " 'fadlalla',\n",
       " 'east',\n",
       " 'asian',\n",
       " 'language',\n",
       " 'berkowski',\n",
       " 'woollacott',\n",
       " 'mcginty',\n",
       " 'fowler',\n",
       " 'zivsak',\n",
       " 'browne',\n",
       " 'wittmerrich',\n",
       " 'margarita',\n",
       " 'nafez',\n",
       " 'kingsberg',\n",
       " 'vossoughi',\n",
       " 'lessing',\n",
       " 'purtle',\n",
       " 'diazsanchez',\n",
       " 'frueh',\n",
       " 'cuartas',\n",
       " 'ppool',\n",
       " 'brody',\n",
       " 'loprinzo',\n",
       " 'merendi',\n",
       " 'yaroslavsky',\n",
       " 'quinn',\n",
       " 'uldall',\n",
       " 'jelani',\n",
       " 'bee',\n",
       " 'doucet',\n",
       " 'piech',\n",
       " 'faglie',\n",
       " 'suzanna',\n",
       " 'mcclain',\n",
       " 'jesper',\n",
       " 'dickson',\n",
       " 'luth',\n",
       " 'duane',\n",
       " 'lan',\n",
       " 'esperance',\n",
       " 'alfred',\n",
       " 'byler',\n",
       " 'adebanjo',\n",
       " 'mccluskey',\n",
       " 'driscoll',\n",
       " 'cesar',\n",
       " 'bagaka',\n",
       " 'huanjing',\n",
       " 'barcarse',\n",
       " 'fabri',\n",
       " 'vanderhill',\n",
       " 'ayee',\n",
       " 'visocky',\n",
       " 'ogrady',\n",
       " 'raghav',\n",
       " 'kavita',\n",
       " 'cooke',\n",
       " 'evan',\n",
       " 'lasine',\n",
       " 'fritz',\n",
       " 'kogan',\n",
       " 'elbert',\n",
       " 'goldinmeadow',\n",
       " 'shubhendu',\n",
       " 'pandey',\n",
       " 'pochiraju',\n",
       " 'pritchard',\n",
       " 'leslie',\n",
       " 'leeper',\n",
       " 'bierly',\n",
       " 'benander',\n",
       " 'wilkerson',\n",
       " 'nealon',\n",
       " 'ausherman',\n",
       " 'jeri',\n",
       " 'awaya',\n",
       " 'smajlagic',\n",
       " 'tabor',\n",
       " 'rogier',\n",
       " 'wrenhaven',\n",
       " 'chartese',\n",
       " 'rathnayake',\n",
       " 'matlack',\n",
       " 'tyrel',\n",
       " 'nikita',\n",
       " 'davor',\n",
       " 'randall',\n",
       " 'kibel',\n",
       " 'koger',\n",
       " 'su',\n",
       " 'stonebraker',\n",
       " 'haleem',\n",
       " 'sipantzi',\n",
       " 'cohee',\n",
       " 'young',\n",
       " 'schwartz',\n",
       " 'gannon',\n",
       " 'metheny',\n",
       " 'serehali',\n",
       " 'banta',\n",
       " 'berker',\n",
       " 'dr',\n",
       " 'greg',\n",
       " 'breanna',\n",
       " 'shwartz',\n",
       " 'wassel',\n",
       " 'adriennie',\n",
       " 'njororai',\n",
       " 'poole',\n",
       " 'devereaux',\n",
       " 'pila',\n",
       " 'cade',\n",
       " 'cao',\n",
       " 'tophoven',\n",
       " 'eustace',\n",
       " 'rawlins',\n",
       " 'dwan',\n",
       " 'sherwood',\n",
       " 'acastelani',\n",
       " 'albanese',\n",
       " 'waymouth',\n",
       " 'ajay',\n",
       " 'kris',\n",
       " 'kenneth',\n",
       " 'fashola',\n",
       " 'dobson',\n",
       " 'ferreria',\n",
       " 'baicker',\n",
       " 'dmitry',\n",
       " 'ronda',\n",
       " 'gatlin',\n",
       " 'mieke',\n",
       " 'joe',\n",
       " 'riskin',\n",
       " 'kiyun',\n",
       " 'hansenthomas',\n",
       " 'bilyk',\n",
       " 'prendergast',\n",
       " 'ernst',\n",
       " 'espinosa',\n",
       " 'brydges',\n",
       " 'marsh',\n",
       " 'wiebe',\n",
       " 'krenzin',\n",
       " 'tuberville',\n",
       " 'mukai',\n",
       " 'mi',\n",
       " 'rountree',\n",
       " 'natural',\n",
       " 'science',\n",
       " 'nackley',\n",
       " 'heter',\n",
       " 'phillips',\n",
       " 'iwuagwu',\n",
       " 'pattersonmartinea',\n",
       " 'pollack',\n",
       " 'adam',\n",
       " 'sawin',\n",
       " 'borkar',\n",
       " 'dava',\n",
       " 'noser',\n",
       " 'ozlem',\n",
       " 'schiavone',\n",
       " 'mauricio',\n",
       " 'yarbrough',\n",
       " 'dima',\n",
       " 'bawendi',\n",
       " 'manuelian',\n",
       " 'bostwick',\n",
       " 'babakhali',\n",
       " 'rizlan',\n",
       " 'cori',\n",
       " 'corren',\n",
       " 'bubonovich',\n",
       " 'mahmud',\n",
       " 'callos',\n",
       " 'ran',\n",
       " 'mcmullen',\n",
       " 'steen',\n",
       " 'noelle',\n",
       " 'spoonts',\n",
       " 'elga',\n",
       " 'pascale',\n",
       " 'hamal',\n",
       " 'bernstein',\n",
       " 'hofmann',\n",
       " 'yimesker',\n",
       " 'latimer',\n",
       " 'scudder',\n",
       " 'manis',\n",
       " 'alhajdarwish',\n",
       " 'mckay',\n",
       " 'cronin',\n",
       " 'jardine',\n",
       " 'ladonna',\n",
       " 'zimmerer',\n",
       " 'kanita',\n",
       " 'jouanwestlund',\n",
       " 'athletic',\n",
       " 'training',\n",
       " 'madanipour',\n",
       " 'rafeeq',\n",
       " 'li',\n",
       " 'moranthomas',\n",
       " 'paganelli',\n",
       " 'emmanuel',\n",
       " 'steedly',\n",
       " 'tanya',\n",
       " 'hector',\n",
       " 'veronne',\n",
       " 'ajaelo',\n",
       " 'hedger',\n",
       " 'chrissy',\n",
       " 'krajewski',\n",
       " 'crouch',\n",
       " 'mohammed',\n",
       " 'vlahos',\n",
       " 'furgerson',\n",
       " 'billing',\n",
       " 'wackerbarth',\n",
       " 'carole',\n",
       " 'cindi',\n",
       " 'jeanie',\n",
       " 'subramani',\n",
       " 'adam',\n",
       " 'von',\n",
       " 'kunes',\n",
       " 'grilliette',\n",
       " 'litchman',\n",
       " 'vijverberg',\n",
       " 'netzel',\n",
       " 'lake',\n",
       " 'roxy',\n",
       " 'byrd',\n",
       " 'crumpler',\n",
       " 'dain',\n",
       " 'michan',\n",
       " 'snavely',\n",
       " 'tabitha',\n",
       " 'kincaid',\n",
       " 'quira',\n",
       " 'mei',\n",
       " 'friesen',\n",
       " 'kirkwood',\n",
       " 'klee',\n",
       " 'tapio',\n",
       " 'redd',\n",
       " 'kuykendall',\n",
       " 'kolick',\n",
       " 'britt',\n",
       " 'barber',\n",
       " 'reedlunn',\n",
       " 'orla',\n",
       " 'jamspal',\n",
       " 'keaton',\n",
       " 'watson',\n",
       " 'jounsup',\n",
       " 'bort',\n",
       " 'rummo',\n",
       " 'bentkowski',\n",
       " 'williams',\n",
       " 'glenn',\n",
       " 'clint',\n",
       " 'valerie',\n",
       " 'kungmcintyre',\n",
       " 'florentin',\n",
       " 'sample',\n",
       " 'heckmann',\n",
       " 'jeanne',\n",
       " 'lidwina',\n",
       " 'jamkartanian',\n",
       " 'abumuhfouz',\n",
       " 'nakia',\n",
       " 'tawny',\n",
       " 'antonio',\n",
       " 'gotlieb',\n",
       " 'asim',\n",
       " 'aharony',\n",
       " 'haryadi',\n",
       " 'damrosch',\n",
       " 'antoinette',\n",
       " 'quella',\n",
       " 'krandel',\n",
       " 'molumby',\n",
       " 'jeane',\n",
       " 'nittono',\n",
       " 'sasuke',\n",
       " 'pauer',\n",
       " 'may',\n",
       " 'quirin',\n",
       " 'witherspoon',\n",
       " 'nina',\n",
       " 'weavercrump',\n",
       " 'williamson',\n",
       " 'harrison',\n",
       " 'lepera',\n",
       " 'andrae',\n",
       " 'saadat',\n",
       " 'bea',\n",
       " 'mathematics',\n",
       " 'statistic',\n",
       " 'rinn',\n",
       " 'aranas',\n",
       " 'carter',\n",
       " 'whitepadgett',\n",
       " 'creep',\n",
       " 'merport',\n",
       " 'basma',\n",
       " 'ika',\n",
       " 'si',\n",
       " 'sumi',\n",
       " 'ludmila',\n",
       " 'groll',\n",
       " 'blau',\n",
       " 'zeus',\n",
       " 'crisler',\n",
       " 'mackay',\n",
       " 'small',\n",
       " 'diamond',\n",
       " 'mahajan',\n",
       " 'kazhdan',\n",
       " 'ticherich',\n",
       " 'macus',\n",
       " 'strong',\n",
       " 'phong',\n",
       " 'k',\n",
       " 'mcvey',\n",
       " 'earth',\n",
       " 'science',\n",
       " 'szefer',\n",
       " 'fensholt',\n",
       " 'mullainathan',\n",
       " 'hick',\n",
       " 'weston',\n",
       " 'leguizamon',\n",
       " 'brooking',\n",
       " 'puckett',\n",
       " 'tartaroglu',\n",
       " 'matthew',\n",
       " 'b',\n",
       " 'viki',\n",
       " 'amonte',\n",
       " 'aliakbar',\n",
       " 'harvey',\n",
       " 'soheil',\n",
       " 'ann',\n",
       " 'muether',\n",
       " 'zoology',\n",
       " 'joao',\n",
       " 'smigelskis',\n",
       " 'pieper',\n",
       " 'dorazio',\n",
       " 'chakraborty',\n",
       " 'thrasher',\n",
       " 'vanburen',\n",
       " 'wilber',\n",
       " 'schilt',\n",
       " 'weidong',\n",
       " 'quintans',\n",
       " 'qian',\n",
       " 'carrie',\n",
       " 'la',\n",
       " 'torre',\n",
       " 'nielson',\n",
       " 'mcclary',\n",
       " 'langlas',\n",
       " 'limbach',\n",
       " 'satterfield',\n",
       " 'slifkin',\n",
       " 'haase',\n",
       " 'lundahl',\n",
       " 'arshad',\n",
       " 'pulianda',\n",
       " 'ferrari',\n",
       " 'littrell',\n",
       " 'allie',\n",
       " 'myose',\n",
       " 'schnee',\n",
       " 'gillum',\n",
       " 'aseel',\n",
       " 'wellington',\n",
       " 'fierston',\n",
       " 'french',\n",
       " 'amp',\n",
       " 'italian',\n",
       " 'zoran',\n",
       " 'bhandal',\n",
       " 'samantha',\n",
       " 'amil',\n",
       " 'yan',\n",
       " 'yan',\n",
       " 'naitee',\n",
       " 'saylerfunk',\n",
       " 'cornett',\n",
       " 'henk',\n",
       " 'millar',\n",
       " 'heyliger',\n",
       " 'shahzad',\n",
       " 'toni',\n",
       " 'walcott',\n",
       " 'romie',\n",
       " 'skipworth',\n",
       " 'danial',\n",
       " 'remani',\n",
       " 'xiaodong',\n",
       " 'judy',\n",
       " 'blythe',\n",
       " 'goodyear',\n",
       " 'panigrahy',\n",
       " 'daniel',\n",
       " 'almousily',\n",
       " 'lesniak',\n",
       " 'hassibi',\n",
       " 'tentawe',\n",
       " 'henebry',\n",
       " 'rarick',\n",
       " 'holmans',\n",
       " 'croxall',\n",
       " 'cheney',\n",
       " 'annette',\n",
       " 'carle',\n",
       " 'hartley',\n",
       " 'jr',\n",
       " 'bellos',\n",
       " 'hopkins',\n",
       " 'stephanie',\n",
       " 'sauerheber',\n",
       " 'jenni',\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('STOPlist.txt') as f:\n",
    "    stoppelop = f.read().splitlines()\n",
    "stoppelop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b805f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225.5741655826569\n"
     ]
    }
   ],
   "source": [
    "#Vectorize - both using count and tfidf\n",
    "\n",
    "start = time.time()\n",
    "#using count and own preprocesser\n",
    "vectorizerc = CountVectorizer(tokenizer=preprocess)\n",
    "\n",
    "# The top N most frequent features:\n",
    "#vectorizerc_most = CountVectorizer(max_features=80, tokenizer=preprocess)\n",
    "\n",
    "#using tfidf vectorizer\n",
    "vectorizertfidf = TfidfVectorizer(tokenizer=preprocess)\n",
    "\n",
    "\n",
    "#Using tfidf vectorizer w highest features\n",
    "#vectorizertfidf = Tfidf_mostVectorizer(tokenizer=preprocess)\n",
    "\n",
    "# fit and transform train and test set for each vectorizer:\n",
    "X_train_c = vectorizerc.fit_transform(X_train)\n",
    "#X_train_c_most = vectorizerc_most.fit_transform(X_train)\n",
    "X_train_tf = vectorizertfidf.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# Only tranform test set: never fit your vectorizer on the test set (it is cheating). Out-of-Vocabulary words are handled automatically be sklearn's vectorizer.\n",
    "X_test_c = vectorizerc.transform(X_test)\n",
    "#X_test_bow = vectorizerc_most.transform(X_test)\n",
    "X_test_tf = vectorizertfidf.transform(X_test)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76619508",
   "metadata": {},
   "source": [
    "### Check difference in precision of count and tf_idf vectorization (using lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff462a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# classifier\n",
    "lr = LogisticRegression(random_state=0, penalty = 'l1', solver = 'saga', max_iter=4000)\n",
    "\n",
    "#training\n",
    "lr.fit(X_train_c,y_train)\n",
    "\n",
    "#testing\n",
    "train_preds = lr.predict(X_train_c)\n",
    "test_preds = lr.predict(X_test_c)\n",
    "print(\"training accuracy:\", np.mean([(train_preds==y_train)]))\n",
    "print(\"testing accuracy:\", np.mean([(test_preds==y_test)]))\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06bdd1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.8096923023554307\n",
      "testing accuracy: 0.7964408367155792\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "lr = LogisticRegression(random_state=0, penalty = 'l1', solver = 'saga')\n",
    "\n",
    "#training\n",
    "lr.fit(X_train_tf,y_train)\n",
    "\n",
    "#testing\n",
    "train_preds = lr.predict(X_train_tf)\n",
    "test_preds = lr.predict(X_test_tf)\n",
    "print(\"training accuracy:\", np.mean([(train_preds==y_train)]))\n",
    "print(\"testing accuracy:\", np.mean([(test_preds==y_test)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e3452b",
   "metadata": {},
   "source": [
    "### Check difference between Lasso and Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd58c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# classifier\n",
    "lr = LogisticRegression(random_state=0, penalty = 'l2', solver = 'saga', max_iter=4000)\n",
    "\n",
    "#training\n",
    "lr.fit(X_train_c,y_train)\n",
    "\n",
    "#testing\n",
    "train_preds = lr.predict(X_train_c)\n",
    "test_preds = lr.predict(X_test_c)\n",
    "print(\"training accuracy:\", np.mean([(train_preds==y_train)]))\n",
    "print(\"testing accuracy:\", np.mean([(test_preds==y_test)]))\n",
    "\n",
    "end = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
